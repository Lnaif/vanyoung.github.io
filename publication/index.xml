<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | HumblePoster</title>
    <link>https://p0st3r.github.io/publication/</link>
      <atom:link href="https://p0st3r.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Lithium©2016</copyright><lastBuildDate>Sun, 12 May 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://p0st3r.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Publications</title>
      <link>https://p0st3r.github.io/publication/</link>
    </image>
    
    <item>
      <title>WebShell detection based on semantic features</title>
      <link>https://p0st3r.github.io/publication/webshell-detection-based-on-semantic-features/</link>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
      <guid>https://p0st3r.github.io/publication/webshell-detection-based-on-semantic-features/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;In order to cope with the current complex and flexible WebShell attack environment and better detect various types of webshells, a text classfication method that combains word2vec and Bi-Gram, which not only considered the semantic features but also the word order features, has a better classfication result than using two features alone.&lt;/p&gt;
&lt;p&gt;In order to cope with the current complex and flexible WebShell attack environment and better detect various types of webshells, an improved WebShell detection method based on CNN was proposed by improving text feature extraction and convolutional neural network structure. First, precompile the PHP data set to get the opcode instruction sequence. Secondly, Word2vec is used to extract the word vectors of the original text and the phrase segmented by bi-gram respectively, and it serves as the two inputs of the convolutional neural network. Finally, the detection is carried out through the designed convolutional neural network. Through experiments, this method effectively improves the accuracy, recall rate and other performance parameters while compared with other methods.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;word-ng-vec&#34;&gt;Word-NG vec&lt;/h3&gt;
&lt;p&gt;In fact, the word embedding learned in Word2vec are more reflect in semantic similarity features , such as &amp;ldquo;extract&amp;rdquo; and &amp;ldquo;take&amp;rdquo;, &amp;ldquo;compression&amp;rdquo; and &amp;ldquo;reduction&amp;rdquo;, but without taking the word order features into account. Sometimes there are some differences with the actual semantics, for example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The USA started a trade war on China&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The main predicates of two sentences are interchanged to express different meanings, but there is no difference in Word2Vec. However, if N-Gram is used to divide the text into word groups , we can obtain the word order feature of the text，such as:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Orignal&lt;/th&gt;
&lt;th&gt;The USA started a trade war on China&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Word2vec&lt;/td&gt;
&lt;td&gt;“The USA”，“started”，&amp;ldquo;a&amp;rdquo;，“trade war”，“on”，“China” (vector)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2-gram&lt;/td&gt;
&lt;td&gt;“The USA/The USA” ，“The USA/started”，&amp;ldquo;stared&amp;rdquo;/a”，“a/trade war”，&amp;ldquo;trade war/on&amp;rdquo;，“on China”&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/blob/master/assets/1.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/raw/master/assets/1.jpg&#34; alt=&#34;1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Combining N-Gram with Word2vec, the word vectors of the original text and 2-gram pharse are both trained by Word2vec as the general features of the text, taking into account not only the semantic features, but also the word order features. In this way, two similar sentences can be correctly classifcated.&lt;/p&gt;
&lt;h3 id=&#34;convolutional-neural-network&#34;&gt;Convolutional Neural Network&lt;/h3&gt;
&lt;p&gt;Based on the Kim Y&amp;rsquo;s 
&lt;a href=&#34;https://arxiv.org/abs/1408.5882&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TextCNN&lt;/a&gt;, combined with the two-channel convolutional neural network, a text classification model DCTF-CNN(Double-Channels and Trible-Filters Convolutional Neural Network) was constructed.&lt;/p&gt;
&lt;p&gt;The structure of the neural network is shown below:&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/blob/master/assets/2.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/raw/master/assets/2.jpg&#34; alt=&#34;2&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The model includes five layers: input layer, convolution layer, pooling layer, full-link layer and output layer.In the input layer, T1 channel and T2 channel respectively input the word vector of the original text and the word vector of the 2-gram pharse. The convolution layer is composed of three convolution kernels of different widths, each of which covers the local characteristics of different granularity.In the pooling layer, the global maximum value is pooled, and the maximum value is reserved for each convolution kernel, which can effectively extract the most representative features.Two feature vectors were spliced in the full link layer, and finally two types of distributions, namely the probability distribution of WebShell and normal files, were output through Softmax in the output layer.&lt;/p&gt;
&lt;h3 id=&#34;php-opcode&#34;&gt;PHP opcode&lt;/h3&gt;
&lt;p&gt;PHP is an interpreted language, and its code execution process can be divided into Lexical Analysis stage, Syntax Analysis stage, byte code compilation stage and code execution stage.The execution flow diagram is shown in the solid line section in the below:&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/blob/master/assets/3.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://github.com/liyuanzi/WordNG-vec_WebShell_detect/raw/master/assets/3.jpg&#34; alt=&#34;3&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the lexical analysis phase, the Lexer reads the source code sequence of characters in sequence and shred them into Token sequences according to PHP syntax rules.In the Syntax analysis stage, the Token sequence is read in by the Parser to be syntactically checked, and then the Abstract Syntax Tree (AST) is generated.In the bytecode compilation phase, the PHP virtual machine Zend reads in the abstract syntax tree and translates the action nodes in the syntax tree into the corresponding bytecode.In the code execution stage, the PHP virtual machine Zend loads the corresponding module according to the code call, initializes the running environment, and finally executes the bytecode instruction and outputs the result.&lt;/p&gt;
&lt;p&gt;For example, the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;?php
echo’Hello World’;
$a=1+1;
echo $a;
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After PHP code compilation by VLD extension, the code can be compiled into following opcode:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ZEND_ECHO ’Hello World’
ZEND_ADD ~ 0 1 1
ZEND_ASSIGN!0 ~ 0
ZEND_ECHI ~ 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this paper, the collected PHP datasets is compiled into opcode to word embedding, so as to avoid the interference of useless annotations added in the WebShell which might bypass static detection. In this way the generalization of the model could be imporved&lt;/p&gt;
&lt;h2 id=&#34;assessment&#34;&gt;Assessment&lt;/h2&gt;
&lt;p&gt;Experimental data sets were obtained from the following sources:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;sources&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;WebShell&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tennc/webshell&#34;&gt;https://github.com/tennc/webshell&lt;/a&gt; &lt;a href=&#34;https://github.com/JohnTroony/php-webshells&#34;&gt;https://github.com/JohnTroony/php-webshells&lt;/a&gt; &lt;a href=&#34;https://github.com/ysrc/webshell-sample&#34;&gt;https://github.com/ysrc/webshell-sample&lt;/a&gt; &lt;a href=&#34;https://github.com/tanjiti/webshellSample&#34;&gt;https://github.com/tanjiti/webshellSample&lt;/a&gt; &lt;a href=&#34;https://github.com/xl7dev/WebShell&#34;&gt;https://github.com/xl7dev/WebShell&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Normal Page&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/WordPress/WordPress&#34;&gt;https://github.com/WordPress/WordPress&lt;/a&gt; &lt;a href=&#34;https://github.com/phpmyadmin/phpmyadmin&#34;&gt;https://github.com/phpmyadmin/phpmyadmin&lt;/a&gt; &lt;a href=&#34;https://github.com/typecho/typecho&#34;&gt;https://github.com/typecho/typecho&lt;/a&gt; &lt;a href=&#34;https://github.com/bcit-ci/CodeIgniter&#34;&gt;https://github.com/bcit-ci/CodeIgniter&lt;/a&gt; &lt;a href=&#34;https://github.com/laravel/laravel&#34;&gt;https://github.com/laravel/laravel&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Remove duplicate files by md5 comparsion, a total of 2387 WebShell samples and 2316 Normal Page samples were obtained.&lt;/p&gt;
&lt;p&gt;The WebShell samples covers One-word Trojan, small Trojan and giant Trojan all types of WebShell.&lt;/p&gt;
&lt;p&gt;The Normal Page covers blog cms，php development framework and database management system, and the similar page was remove to optimize data sets.&lt;/p&gt;
&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;p&gt;Download code and data sets&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/liyuanzi/WordNG-vec_WebShell_detect
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This code requires Python2.7&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda create --name py27 python=2.7
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Initialization environment&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install -r requerments.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;start trainning&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nohup python -u webshell.py &amp;gt;dctf.txt 2&amp;gt;&amp;amp;1 &amp;amp; tail -f dctf.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The word embedding process takes a very long time，use &lt;code&gt;nohup&lt;/code&gt; to avoid the word embedding process fail because the terminal closed unexpectly. The result is loaded into &lt;code&gt;dctf.txt&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;A Comparsion examination on a small size data sets .&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;features&lt;/th&gt;
&lt;th&gt;Accuracy&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;F1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2-gram&lt;/td&gt;
&lt;td&gt;0.798&lt;/td&gt;
&lt;td&gt;0.714&lt;/td&gt;
&lt;td&gt;0.196&lt;/td&gt;
&lt;td&gt;0.308&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;opcode sequences&lt;/td&gt;
&lt;td&gt;0.969&lt;/td&gt;
&lt;td&gt;0.998&lt;/td&gt;
&lt;td&gt;0.823&lt;/td&gt;
&lt;td&gt;0.902&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Word2vec&lt;/td&gt;
&lt;td&gt;0.958&lt;/td&gt;
&lt;td&gt;0.994&lt;/td&gt;
&lt;td&gt;0.918&lt;/td&gt;
&lt;td&gt;0.954&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bigram-word2vec&lt;/td&gt;
&lt;td&gt;0.960&lt;/td&gt;
&lt;td&gt;0.978&lt;/td&gt;
&lt;td&gt;0.937&lt;/td&gt;
&lt;td&gt;0.958&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Word-NG vec&lt;/td&gt;
&lt;td&gt;0.984&lt;/td&gt;
&lt;td&gt;0.995&lt;/td&gt;
&lt;td&gt;0.971&lt;/td&gt;
&lt;td&gt;0.982&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>MS08-067漏洞原理及复现分析</title>
      <link>https://p0st3r.github.io/publication/ms-08-067-analyise/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://p0st3r.github.io/publication/ms-08-067-analyise/</guid>
      <description>&lt;h2 id=&#34;445端口&#34;&gt;445端口&lt;/h2&gt;
&lt;p&gt;首先介绍一下这个引发了诸多特大漏洞的445端口。&lt;/p&gt;
&lt;p&gt;TCP 445端口主要运行两种服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SMB 网络服务&lt;/li&gt;
&lt;li&gt;MSRPC 网络服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**SMB（Server Message Block，服务器消息块）**首先提供了 Windows 网络中最常用的远程文件与打印机共享网络服务，其次，SMB的命名管道是 MSRPC 协议认证和调用本地服务的承载传输层。&lt;/p&gt;
&lt;p&gt;SMB 作为应用层协议，其直接运行在TCP 445端口上，也可通过调用 NBT 的 TCP 139端口来接收数据。&lt;/p&gt;
&lt;p&gt;**MSRPC（Microsoft Remote Procedure Call，微软远程过程调用）**是对 DCE/RPC 在 Windows 系统下的重新改进和实现，用以支持Windows系统中的应用程序能够无缝地通过网络调用远程主机上服务进程中的过程。&lt;/p&gt;
&lt;p&gt;DCE/RPC 独立运行于网络传输层协议上，采用的网络传输层协议包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ncacn_ip_tcp =&amp;gt; TCP 139&lt;/li&gt;
&lt;li&gt;ncadg_ip_udp =&amp;gt; UDP 135&lt;/li&gt;
&lt;li&gt;ncacn_np =&amp;gt; TCP 139、445&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，主要使用的是 ncacn_np（SMB命名管道传输协议），也就是利用 SMB 命名管道机制作为 RPC 的承载传输协议（MSRPC over SMB）。&lt;/p&gt;
&lt;p&gt;只有少数如MS09-050是直接针对SMB服务的，而MSRPC作为调用大量本地服务进程的网络接口，常常被利用 MSRPC over SMB 为通道如MS08-067来攻击本地服务中存在的安全漏洞。&lt;/p&gt;
&lt;h1 id=&#34;0x01-ms08-067漏洞原理&#34;&gt;0x01 MS08-067漏洞原理&lt;/h1&gt;
&lt;p&gt;MS08-067漏洞是通过 MSRPC over SMB 通道调用 Server 服务程序中的 NetPathCanonicalize 函数时触发的，而 NetPathCanonicalize 函数在远程访问其他主机时，会调用 NetpwPathCanonicalize 函数，对远程访问的路径进行规范化，而在 NetpwPathCanonicalize 函数中存在的逻辑错误，造成栈缓冲区可被溢出，而获得远程代码执行（Remote Code Execution）。&lt;/p&gt;
&lt;p&gt;所谓路径规范化，就是将路径字符串中的【/】转换为【\】，同时去除相对路径【.\】和【..\】。如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;**/*/./**   =&amp;gt;  **\*\**
**\*\..\**  =&amp;gt;  **\**
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在路径规范化的操作中，服务程序对路径字符串的地址空间检查存在逻辑漏洞。攻击者通过精心设计输入路径，可以在函数去除【..\】字符串时，把路径字符串中内容复制到路径串之前的地址空间中（低地址），达到覆盖函数返回地址，执行任意代码的目的。&lt;/p&gt;
&lt;h2 id=&#34;路径处理流程&#34;&gt;路径处理流程&lt;/h2&gt;
&lt;p&gt;NetpwPathCanonicalize 函数并没有直接进行输入路径和规范化，而是继续调用了下级函数CanonicalizePathName 来进行路径整理，将待整理的路径字符串进行规范化，然后再&lt;strong&gt;保存到预先分配的输出路径缓冲区buffer中&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;路径处理流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检查待整理路径的第一个字符&lt;/li&gt;
&lt;li&gt;调用msvcrt.dll模块的wcslen函数计算路径长度&lt;/li&gt;
&lt;li&gt;调用msvcrt.dll模块的wcscat函数把待整理路径全部复制到新申请的内存中&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;\4. 调用wcscpy函数，去掉待整理路径中第一个表示父目录的相对路径复制到strTemp，如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;\******\..\..\***   =&amp;gt;  \..\***
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;5.循环调用wcscpy，直到路径整理完毕&lt;/p&gt;
&lt;p&gt;在这里我们知道了，在规范化复制时要寻找表示父目录的【..\】字符串及其前面的一个【\】字符串，将这一段去掉并将新路径复制。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;v2-a227e632597e472caec3c37457455d8a_hd.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;如图，第一次检查时去掉了第一个相对路径并复制到缓冲区&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是，当【..\】字符串在路径字符串的最前面时，那么其前面的一个【\】就在缓冲区外面了，就是在这里产生了向前（低地址）的溢出。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;v2-9709d2768dff1383b5a1dbb6567016a1_hd.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;缓冲区溢出&#34;&gt;缓冲区溢出&lt;/h2&gt;
&lt;p&gt;需要明确的是，微软对路径规范化时的字符串复制可能出现的缓冲区溢出做了初步的防御。&lt;/p&gt;
&lt;p&gt;在每次向缓冲区中复制字符串时，无论是用 wcsccpy 还是 wcscat，在复制前总要比较源字符串的长度，保证长度小于某个值（207），否则不会继续复制，这一策略确保缓冲区不会向高地址溢出，即当前函数返回时不会发生问题。&lt;/p&gt;
&lt;p&gt;**但是注意，**在规范化表示路径，寻找父目录的【..\】字符串前面的【\】字符时，程序做了判断和边界检查：如果当前比较字符的地址与源字符串地址相同，就表明整个字符串已经查找完毕，程序就会停止查找。&lt;/p&gt;
&lt;p&gt;然而它唯独漏了一种情况，就是当父目录相对路径【..\】字符串在源字符串的开头时，在开始查找时比较的字符串(【\】到【..\】)位于缓冲区之外，这导致了复制的字符串向低地址的溢出，造成函数wcscpy的返回地址被覆盖。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;v2-f51502175256d3571f471872250a7d2a_hd.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;0x02-漏洞还原分析&#34;&gt;0x02 漏洞还原分析&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;实验环境&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;靶机 Windows2003 SP0 EN&lt;/li&gt;
&lt;li&gt;漏洞组件 netapi32.dll&lt;/li&gt;
&lt;li&gt;工具 IDA Pro、OllyDbg&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择 Windows XP SP3 EN 系统主机作为分析环境，定位到包含该安全漏洞的系统模块netapi32.dll（路径C:\Windows\system32）和调用漏洞服务 Server 的进程 svchost.exe，目标进程命令行为&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;C:\Windows\System32\svchost.exe-k netsvcs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;用 IDA pro 打开 netapi32.dll，找到漏洞所在的 NetpwPathCanonicalize 函（每次运行堆栈中的地址会不同，但各函数的地址一样），如图在书中提到&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;查看该函数流程图，可以看到，此函数并没有直接进行输入路径的规范化， 而是继续调用了下级函数 CanonicalizePathName&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然而在实际操作中并没有发现 CanonicalizePathName 这个函数，并且多种资料表明应当是调用 CanonPathName 函数进行规范化。&lt;/p&gt;
&lt;p&gt;IDA分析 NetpwPathCanonicalize 函数代码（F5 + 整理 + 主要代码）：&lt;/p&gt;
&lt;p&gt;该函数声明如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;DWORD NetpwPathCanonicalize(
    LPWSTR PathName, &lt;span style=&#34;color:#75715e&#34;&gt;//需要标准化的路径
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    LPWSTR Outbuf, &lt;span style=&#34;color:#75715e&#34;&gt;//存储标准化后的路径的Buffer
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    DWORD OutbufLen, &lt;span style=&#34;color:#75715e&#34;&gt;//Buffer长度
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    LPWSTR Prefix, &lt;span style=&#34;color:#75715e&#34;&gt;//可选参数，当PathName是相对路径时有用
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    LPDWORD PathType, &lt;span style=&#34;color:#75715e&#34;&gt;//存储路径类型
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    DWORD Flags &lt;span style=&#34;color:#75715e&#34;&gt;// 保留，为0
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt; )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;动态调试&#34;&gt;动态调试&lt;/h2&gt;
&lt;p&gt;通过wmic查看命令行参数为svchost.exe -k netsvcs的进程pid&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;v2-1288255ae58fb85ca4ac480f2c53a1e0_hd.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;打开OllyDbg，点击file-&amp;gt;attach，附着到svchost.exe进程上&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557342950869.png&#34; alt=&#34;1557342950869&#34;&gt;&lt;/p&gt;
&lt;p&gt;View-&amp;gt;Executable modules双击netapi32，在cpu指令窗口右键选Search for查找exec(label) in current module，找到函数NetpwPathCanonicalize，地址为71C44A3E，在此处设下断点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343007573.png&#34; alt=&#34;1557343007573&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;追踪漏洞触发过程&#34;&gt;追踪漏洞触发过程&lt;/h2&gt;
&lt;p&gt;回到CPU指令窗口运行程序，然后攻击机Metasploit加载ms08_067_netapi模块并exploit&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343016344.png&#34; alt=&#34;1557343016344&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;netpwpathcanonicalize中断&#34;&gt;NetpwPathCanonicalize中断&lt;/h3&gt;
&lt;p&gt;分析环境中的svchost程序会中断在 NetpwPathCanonicalize 函数的入口地址处。该函数的传入参数如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343159242.png&#34; alt=&#34;1557343159242&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esp    		[esp]		* 注释 *
00ECF924	02248D34	;指向待整理路径
00ECF928	022321D8	;指向输出路径buffer
00ECF92C	000003F1	;输出buffer的长度
00ECF930	02248FB0	;指向prefix，值为 \x5C\x00 ，即unicode ‘\’
00ECF934	02248FB4	;指向路径类型，值为 0x1001
00ECF938	00000000	;WORD Flags保留，值为0
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;canonicalizepathname中断&#34;&gt;CanonicalizePathName中断&lt;/h3&gt;
&lt;p&gt;结合IDA pro对 NetpwPathCanonicalize 的流程分析，在 地址处将调用下一级函数 CanonPathName，在此地址设下断点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343329568.png&#34; alt=&#34;1557343329568&#34;&gt;&lt;/p&gt;
&lt;p&gt;运行到此断点，然后跟踪函数 CanonPathName，传入参数如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;00F0F8FC	00157570	;指向prefix，值为\x5C\00，即Unicode&amp;#34;\&amp;#34;
00F0F900	001572F4	;指向待整理路径
00F0F904	02132E80	;指向输出路径的buffer
00F0F908	000003F9	;输出buffer的长度
00F0F90C	00000000	;WORD Flag保留字，值为0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从上两个函数的参数传递可以看出，函数 CanonPathName 进行路径整理，然后再保存到预先分配的输出路径缓冲区buffer中。&lt;/p&gt;
&lt;h3 id=&#34;待整理路径结构&#34;&gt;待整理路径结构&lt;/h3&gt;
&lt;p&gt;在OD中查看待整理路径的结构，路径是Unicode字符串，以【\x5C\x00】(Unicode字符“\”)开始，【\x00\x00】结束，中间包含一些随机的大小写字母，较长一段不可显示的字符是经过编码的Shellcode，其中最关键的是两个连在一起的父目录相对路径【....\】。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343359609.png&#34; alt=&#34;1557343359609&#34;&gt;&lt;/p&gt;
&lt;p&gt;整个待整理路径形如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;\******\..\..\***
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;整理路径前的预操作&#34;&gt;整理路径前的预操作&lt;/h3&gt;
&lt;p&gt;在待整理路径所在内存地址000C0F50处4字节上设内存访问断点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343390836.png&#34; alt=&#34;1557343390836&#34;&gt;&lt;/p&gt;
&lt;p&gt;按F9运行，会中断3次，前两次分别是检查待整理路径的第一个字符和调用wcslen函数，第三次是在调用wcscat函数。分析第三次传入栈中两个参数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343410176.png&#34; alt=&#34;1557343410176&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一个是strDestination，指向一段以【\x5c\x00】开头的内存空间；第二个是strSource，指向上述待整理路径前两字节【\x5c\x00】后的内容。&lt;/p&gt;
&lt;p&gt;程序把待整理路径全部复制到strDestination，即0x001572F6处。在此4字节设断点，类型选择&amp;quot;Hardware, on access&amp;quot;DWord。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343435014.png&#34; alt=&#34;1557343435014&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;复制路径到缓冲区&#34;&gt;复制路径到缓冲区&lt;/h3&gt;
&lt;p&gt;F9继续运行，第4次中断在0x77BD4010 ，内存里显示这里将src的前两个字符复制到了dest的【\x5C\x00】后面，这是由于这两个字节设了断点的原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343573648.png&#34; alt=&#34;1557343573648&#34;&gt;&lt;/p&gt;
&lt;p&gt;第5次中断在0x71C44B1C，位于wcscat函数内，内存显示已将src复制到dest，如图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343589111.png&#34; alt=&#34;1557343589111&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343606903.png&#34; alt=&#34;1557343606903&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;第一次路径规范化&#34;&gt;第一次路径规范化&lt;/h3&gt;
&lt;p&gt;按F9运行，中断多次后停在内存0x77bd4d36处，通过栈可知此处属于wcscpy函数。此处调用该函数进行第一次路径规范化。如图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343631915.png&#34; alt=&#34;1557343631915&#34;&gt;&lt;/p&gt;
&lt;p&gt;当前参数src值为0x00EC6E0，指向【..***】;参数 strDestination 值为0x00ECF4DC，指向temp中的第一个字符【\】。 显然，这次路径规范化即把待整理路径中第一个字符【\】和第一个【..\】相对路径之间的内容抛弃。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343644183.png&#34; alt=&#34;1557343644183&#34;&gt;&lt;/p&gt;
&lt;p&gt;而此时wcscpy源地址src在edx寄存器中，指向【..***】；目的地址dest在ecx寄存器中，指向待整理路径第一个字符【\】，如图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343668919.png&#34; alt=&#34;1557343668919&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以，这次字符串复制操作就是去掉第一个表示父目录的相对路径，即待整理路径temp中的第一个【\】和第一个【..\】之间的内容成为无用路径被抛弃。操作完成后，temp中的路径字符形如【..***】。&lt;/p&gt;
&lt;p&gt;第一次规范化后，待整理路径形如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;\..\***
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于还有【..\】，还需要进行一次规范化，而这第二次规范化正是玄机所在。&lt;/p&gt;
&lt;h3 id=&#34;第二次路径规范化&#34;&gt;第二次路径规范化&lt;/h3&gt;
&lt;p&gt;由于每次路径规范化都会调用wcscpy函数，接下来删除0x00ECF4DC的硬件断点，直接在wcscpy函数的入口地址0x77BD4D28处下断点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343841212.png&#34; alt=&#34;1557343841212&#34;&gt;&lt;/p&gt;
&lt;p&gt;F9运行后中断在wcscpy函数入口0x77BD4D28处，调用wcscpy函数传入的参数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343857034.png&#34; alt=&#34;1557343857034&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esp			[esp]		* 注释 *
00ECF4AC	00ECF494	目的地址，指向的内存区域值为\x5c\x00，即【\】
00ECF4B0	00ECF4E2	源地址，指向第二个相对路径【\..\】的最后一个斜杠
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;正常情况下，这次规范化处理会和第一次执行同样的操作，去除第二个相对路径【..\】，从而完成第二次的路径规范化。但这里出现了一个意外的情况，temp的首地址是0x00ECF4DC，而此次字符串复制操作的目的地址dest却在0x00ECF494，在temp之前，如图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343903100.png&#34; alt=&#34;1557343903100&#34;&gt;&lt;/p&gt;
&lt;p&gt;同时注意到，栈指针ESP值为0x00ECF4A8，该地址指向wcscpy函数的返回地址0x71C52FD4。ESP到复制目的dest地址0x00ECF494只有0x14字节，于是，函数wcscpy如果继续执行，将用源字符串src覆盖wcscpy函数的返回地址。&lt;/p&gt;
&lt;p&gt;执行到retn命令，可以看到返回地址变成了0x0100129E，，该地址的指令为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;00100129E		FFD6		call esi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;执行 call esi（ES=0x00F0F4DE）指令，正好将EIP指向复制尽量的字符串中构造好的第8字节空指令，接着是【\xeb\x62】（jmp 0x62），此jmp指令跳过中间的随机字符串，指向经过编码的Shellcode，如图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;1557343946968.png&#34; alt=&#34;1557343946968&#34;&gt;&lt;/p&gt;
&lt;p&gt;所以这里是由于内存0x00F0F494处的一个【\】(0x5C)，使得出现在处理父母了相对路径【..\】时往前溢出了待处理路径，从而将字符串覆盖到函数wcscpy返回地址的位置，跳转到shellcode造成远程代码执行。&lt;/p&gt;
&lt;p&gt;正如前面所提到的，当【..\】在源字符串开头的时候，在开始查找时，比较的字符位于缓冲区之外导致了向前的溢出。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
